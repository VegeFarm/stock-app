import io
import os
import re
import json
import math
import shutil
from decimal import Decimal
from datetime import datetime, timedelta, timezone
from pathlib import Path
from zoneinfo import ZoneInfo
from collections import defaultdict, OrderedDict
from typing import Optional, Tuple, List, Dict

import pandas as pd
import streamlit as st
import openpyxl

# -------------------- Optional deps --------------------
# Excel decrypt (SmartStore password 0000)
try:
    import msoffcrypto
except ModuleNotFoundError:
    msoffcrypto = None

# PDF screenshot render (PyMuPDF)
try:
    import fitz  # PyMuPDF (pymupdf)
except Exception:
    fitz = None

# Pillow (merge PNG pages -> one PNG)
try:
    from PIL import Image
except Exception:
    Image = None

# PDF text extract libs
try:
    import pdfplumber
except Exception:
    pdfplumber = None

try:
    from pypdf import PdfReader
except Exception:
    try:
        from PyPDF2 import PdfReader  # fallback
    except Exception:
        PdfReader = None

# ReportLab (PDFs)
from reportlab.platypus import (
    SimpleDocTemplate,
    Table,
    LongTable,
    TableStyle,
    Paragraph,
    Spacer,
    KeepTogether,
    HRFlowable,
)
from reportlab.pdfgen import canvas
from reportlab.lib.pagesizes import A4, landscape
from reportlab.lib import colors
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.lib.units import mm
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.ttfonts import TTFont
from reportlab.pdfbase.cidfonts import UnicodeCIDFont


# =====================================================
# TIMEZONE
# =====================================================
KST_TZ = ZoneInfo("Asia/Seoul")
KST = timezone(timedelta(hours=9))  # for legacy functions


def now_prefix_kst() -> str:
    return datetime.now(KST).strftime("%Y%m%d_%H%M%S")


# =====================================================
# PATHS / STORAGE
# =====================================================
# (1) ì¬ê³ ê´€ë¦¬ ì €ì¥
INVENTORY_FILE = "inventory.csv"

# (2) PACK/BOX/EA ê·œì¹™(ì œí’ˆë³„ í•©ê³„ ê³„ì‚°ìš©)
RULES_FILE = "rules.txt"
COUNT_UNITS = ["ê°œ", "í†µ", "íŒ©", "ë´‰"]

# (3) 2ë²ˆ ì½”ë“œ(ì—‘ì…€ ì—…ë¡œë“œ/ë§¤ì¹­ ê·œì¹™) ë°ì´í„° ì €ì¥
DATA_DIR = Path("data")
DATA_DIR.mkdir(exist_ok=True)

MAPPING_PATH = DATA_DIR / "name_mappings.json"
EXPR_RULES_PATH = DATA_DIR / "expression_rules.json"
BACKUP_DIR = DATA_DIR / "rules_backup"
BACKUP_DIR.mkdir(exist_ok=True)

# âœ… TC ì„¤ì • ì €ì¥ íŒŒì¼ (í”„ë¡œê·¸ë¨ ê»ë‹¤ ì¼œë„ ìœ ì§€)
TC_SETTINGS_PATH = DATA_DIR / "tc_settings.json"

# âœ… ìŠ¤í‹°ì»¤ ì œì™¸ ì„¤ì • ì €ì¥ íŒŒì¼ (í”„ë¡œê·¸ë¨ ê»ë‹¤ ì¼œë„ ìœ ì§€)
STICKER_SETTINGS_PATH = DATA_DIR / "sticker_settings.json"

# âœ… ë ˆí¬(ì•± í´ë”)ì— "TCì£¼ë¬¸_ë“±ë¡ì–‘ì‹.xlsx" íŒŒì¼ì„ ê°™ì´ ì˜¬ë ¤ë‘ë©´ ì—…ë¡œë“œ ì—†ì´ ìë™ ì‚¬ìš©
TC_TEMPLATE_DEFAULT_PATH = Path("TCì£¼ë¬¸_ë“±ë¡ì–‘ì‹.xlsx")

# âœ… SmartStore ì—‘ì…€ ë¹„ë²ˆ
EXCEL_PASSWORD = "0000"

# -------------------- Export helpers (inventory snapshots) --------------------
EXPORT_ROOT = "exports"


def kst_date_folder() -> str:
    return datetime.now(KST).strftime("%Y.%m.%d")


def ensure_export_root() -> str:
    try:
        os.makedirs(EXPORT_ROOT, exist_ok=True)
    except Exception:
        pass
    return EXPORT_ROOT


def export_inventory_snapshot(df: pd.DataFrame) -> tuple[str, str]:
    """
    ì¬ê³ í‘œ(df)ë¥¼ exports/YYYY.MM.DD/ì¬ê³ í‘œ_YYYY.MM.DD.xlsx ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    ê°™ì€ ë‚ ì§œì— ì—¬ëŸ¬ ë²ˆ ë‚´ë³´ë‚´ê¸°ë¥¼ ëˆ„ë¥´ë©´ íŒŒì¼ì€ ë®ì–´ì”ë‹ˆë‹¤.
    """
    ensure_export_root()
    date_str = kst_date_folder()
    folder = os.path.join(EXPORT_ROOT, date_str)
    os.makedirs(folder, exist_ok=True)

    file_path = os.path.join(folder, f"ì¬ê³ í‘œ_{date_str}.xlsx")
    data = inventory_df_to_xlsx_bytes(df)
    with open(file_path, "wb") as f:
        f.write(data)
    return date_str, file_path


def list_export_dates() -> list[str]:
    ensure_export_root()
    try:
        names = os.listdir(EXPORT_ROOT)
    except Exception:
        return []

    out: list[str] = []
    for name in names:
        p = os.path.join(EXPORT_ROOT, name)
        if os.path.isdir(p) and re.fullmatch(r"\d{4}\.\d{2}\.\d{2}", name):
            out.append(name)

    out.sort(reverse=True)
    return out


def read_export_xlsx_bytes(date_str: str) -> bytes | None:
    p = os.path.join(EXPORT_ROOT, date_str, f"ì¬ê³ í‘œ_{date_str}.xlsx")
    if not os.path.exists(p):
        return None
    try:
        with open(p, "rb") as f:
            return f.read()
    except Exception:
        return None


def delete_export_date(date_str: str) -> bool:
    """exports/YYYY.MM.DD í´ë”(í•´ë‹¹ ë‚ ì§œ ë‚´ë³´ë‚´ê¸°)ë¥¼ í†µì§¸ë¡œ ì‚­ì œ"""
    ensure_export_root()
    if not re.fullmatch(r"\d{4}\.\d{2}\.\d{2}", (date_str or "")):
        return False

    folder = os.path.join(EXPORT_ROOT, date_str)

    # ì•ˆì „ì¥ì¹˜: exports í´ë” ë°–ì„ ì‚­ì œí•˜ì§€ ì•Šë„ë¡ ê²½ë¡œ ê²€ì¦
    root_abs = os.path.abspath(EXPORT_ROOT)
    folder_abs = os.path.abspath(folder)
    if not folder_abs.startswith(root_abs):
        return False

    if os.path.isdir(folder_abs):
        shutil.rmtree(folder_abs)
        return True
    return False


# =====================================================
# âœ… ì œí’ˆë³„ í•©ê³„ ê³ ì • ìˆœì„œ(í‘œì— í•­ìƒ ë¨¼ì €, ìœ„â†’ì•„ë˜ ê¸°ì¤€)
# =====================================================
FIXED_PRODUCT_ORDER = [
    "ê³ ìˆ˜",
    "ê³µì‹¬ì±„",
    "ê·¸ë¦°ë¹ˆ",
    "ë‹¹ê·€ì",
    "ë”œ",
    "ë˜ë””ì‰¬",
    "ë¡œì¦ˆë§ˆë¦¬",
    "ë¡œì¼€íŠ¸",
    "ë°”ì§ˆ",
    "ë¡œì¦ˆì",
    "ë¹„íƒ€ë¯¼",
    "ìŒˆìƒëŸ¬ë¦¬",
    "ìŒˆì¶”",
    "ì• í”Œë¯¼íŠ¸",
    "ì™€ì¼ë“œ",
    "ìë¡œë©”ì¸",
    "ì ê²¨ì",
    "ì ê·¼ëŒ€",
    "ì ì¹˜ì»¤ë¦¬",
    "ì²­ê²½ì±„",
    "ì²­ì¹˜ì»¤ë¦¬",
    "ì¼€ì¼",
    "íƒ€ì„",
    "í†µë¡œë©”ì¸",
    "í–¥ë‚˜ë¬¼",
    "ë‰´ê·¸ë¦°",
    "ì²˜ë¹Œ",
]


# =====================================================
# (A) PACK/BOX/EA ê·œì¹™ (1ë²ˆì½”ë“œ)
# =====================================================
def norm_type(t: str) -> str:
    t = (t or "").strip()
    if t in ["íŒ©", "PACK", "pack", "Pack"]:
        return "PACK"
    if t in ["ë°•ìŠ¤", "BOX", "box", "Box"]:
        return "BOX"
    if t in ["ê°œ", "EA", "ea", "Each", "EACH"]:
        return "EA"
    return t.upper().strip()


def display_type(typ: str) -> str:
    typ = norm_type(typ)
    return {"PACK": "íŒ©", "BOX": "ë°•ìŠ¤", "EA": "ê°œ"}.get(typ, typ)


def parse_pack_size_g(val: str) -> float:
    """(PACK/EA) ê°’: 500 / 500g / 0.5kg í—ˆìš© -> gë¡œ ë°˜í™˜"""
    v = (val or "").strip().lower().replace(" ", "")
    if v.endswith("kg"):
        return float(v[:-2]) * 1000.0
    if v.endswith("g"):
        return float(v[:-1])
    return float(v)


def parse_box_size_kg(val: str) -> float:
    """(BOX) ê°’: 2 / 2kg / 2000g í—ˆìš© -> kgë¡œ ë°˜í™˜"""
    v = (val or "").strip().lower().replace(" ", "")
    if v.endswith("g"):
        return float(v[:-1]) / 1000.0
    if v.endswith("kg"):
        return float(v[:-2])
    return float(v)


def load_rules_text() -> str:
    if os.path.exists(RULES_FILE):
        try:
            with open(RULES_FILE, "r", encoding="utf-8") as f:
                return f.read()
        except Exception:
            pass

    return """# TYPE,ìƒí’ˆëª…,ê°’
# íŒ©(PACK),ìƒí’ˆëª…,íŒ©_ê¸°ì¤€_g(=1íŒ©ì´ ëª‡ gì¸ì§€)  ex) 500 / 500g / 0.5kg
# ë°•ìŠ¤(BOX),ìƒí’ˆëª…,ë°•ìŠ¤_ê¸°ì¤€_kg(=1ë°•ìŠ¤ê°€ ëª‡ kgì¸ì§€) ex) 2 / 2kg / 2000g
# ê°œ(EA),ìƒí’ˆëª…,1ê°œ_ê¸°ì¤€_g(=1ê°œê°€ ëª‡ gì¸ì§€) ex) 1kg / 500g
#
# âœ… ì¶œë ¥ ê·œì¹™
# - í™”ë©´/ê²°ê³¼ëŠ” ëª¨ë‘ ìˆ«ìë§Œ ì¶œë ¥(ë‹¨ìœ„ ê¸€ì ì—†ìŒ)
# - BOX ë“±ë¡ ìƒí’ˆì€ 1 ë¯¸ë§Œì´ì–´ë„ ë‚˜ëˆ ì„œ í‘œì‹œ (ì˜ˆ: 600g / 2000g = 0.3)

íŒ©,ê±´ëŒ€ì¶”,500
íŒ©,ì–‘ì†¡ì´,500

ë°•ìŠ¤,ì ê²¨ì,2
ë°•ìŠ¤,ì ê·¼ëŒ€,2

# ì˜ˆ) ê°œ,ê¹ë§ˆëŠ˜,1kg  -> í•©ê³„ 10kgì´ë©´ 10(ìˆ«ìë§Œ)ë¡œ í‘œì‹œ(ì •ìˆ˜ì¼ ë•Œë§Œ)
"""


def save_rules_text(text: str) -> None:
    with open(RULES_FILE, "w", encoding="utf-8") as f:
        f.write(text or "")


def parse_rules(text: str):
    pack_rules = {}  # {ìƒí’ˆëª…: {"size_g": float}}
    box_rules = {}   # {ìƒí’ˆëª…: {"size_kg": float}}
    ea_rules = {}    # {ìƒí’ˆëª…: {"size_g": float}}

    for raw in (text or "").splitlines():
        line = raw.strip()
        if not line or line.startswith("#"):
            continue

        parts = [p.strip() for p in line.split(",")]
        if len(parts) < 3:
            continue

        typ = norm_type(parts[0])
        name = parts[1].strip()
        val_raw = parts[2].strip()

        try:
            if typ == "PACK":
                size_g = parse_pack_size_g(val_raw)
                if size_g > 0:
                    pack_rules[name] = {"size_g": size_g}

            elif typ == "BOX":
                size_kg = parse_box_size_kg(val_raw)
                if size_kg > 0:
                    box_rules[name] = {"size_kg": size_kg}

            elif typ == "EA":
                size_g = parse_pack_size_g(val_raw)
                if size_g > 0:
                    ea_rules[name] = {"size_g": size_g}
        except Exception:
            continue

    return pack_rules, box_rules, ea_rules


def upsert_rule(text: str, typ: str, name: str, val: str) -> str:
    typ_norm = norm_type(typ)
    typ_disp = display_type(typ_norm)

    name = (name or "").strip()
    val = (val or "").strip()
    if not typ_norm or not name or not val:
        return text

    lines = (text or "").splitlines()
    out = []
    replaced = False

    for ln in lines:
        if ln.strip().startswith("#") or not ln.strip():
            out.append(ln)
            continue

        parts = [p.strip() for p in ln.split(",")]
        if len(parts) >= 2 and norm_type(parts[0]) == typ_norm and parts[1] == name:
            out.append(f"{typ_disp},{name},{val}")
            replaced = True
        else:
            out.append(ln)

    if not replaced:
        if out and out[-1].strip() != "":
            out.append("")
        out.append(f"{typ_disp},{name},{val}")

    return "\n".join(out)


# =====================================================
# (B) 2ë²ˆ ì½”ë“œ: ë§¤ì¹­/í‘œí˜„ ê·œì¹™ + ì—‘ì…€ ì²˜ë¦¬ + PDF/TC ì¶œë ¥
# =====================================================
UNIT_PATTERNS = [
    r"\d+(?:\.\d+)?kg\s*~\s*\d+(?:\.\d+)?kg",
    r"\d+(?:\.\d+)?kg",
    r"(?:ì•½\s*)?\d+(?:\.\d+)?g",
    r"\d+ê°œ",
    r"\d+í†µ",
    r"\d+ë‹¨",
    r"\d+ë´‰",
    r"\d+íŒ©",
]
UNIT_RE = re.compile(r"(" + "|".join(UNIT_PATTERNS) + r")")


def extract_variant(name: str) -> str:
    s = (name or "").strip()
    m = UNIT_RE.search(s)
    if not m:
        return ""
    u = m.group(0)
    u = re.sub(r"\s+", "", u)
    u = u.replace("ì•½", "")
    if "~" in u:
        u = u.split("~", 1)[1]
    return u


def normalize_text(s: str) -> str:
    s = (s or "").strip()
    s = re.sub(r"\s+", " ", s)
    return s


def _safe_int(v) -> Optional[int]:
    if v is None or (isinstance(v, float) and pd.isna(v)):
        return None
    try:
        return int(v)
    except Exception:
        return None


def _xml_escape(s: str) -> str:
    s = str(s or "")
    return s.replace("&", "&amp;").replace("<", "&lt;").replace(">", "&gt;")


def _text_width_pt(text: str, font: str, size: float) -> float:
    try:
        w = pdfmetrics.stringWidth(text, font, size)
        if not w or w <= 0:
            return len(text) * size * 0.55
        return w
    except Exception:
        return len(text) * size * 0.55


def fmt_qty(x):
    try:
        x = float(x)
        return int(x) if x.is_integer() else x
    except Exception:
        return x


def _as_int_qty(v) -> int:
    try:
        f = float(v)
        if abs(f - round(f)) < 1e-9:
            return int(round(f))
        return int(round(f))
    except Exception:
        return 0


# -------------------- TC defaults --------------------
TC_PRODUCT_NAME_FIXED = "ì±„ì†ŒíŒœìƒí’ˆ"
TC_ACCESS_FALLBACK = "ê²½ë¹„ì‹¤ í˜¸ì¶œ"
TC_TYPE_DAWN_DEFAULT = "ìë™"
TC_TYPE_NEXT_DEFAULT = "íƒë°°ëŒ€í–‰"

# ìˆ˜ì·¨ì¸ë³„ PDF ìŠ¤íƒ€ì¼
RECIPIENT_FONT_SIZE = 12
RECIPIENT_LEADING = 15
RECIPIENT_BLOCK_GAP_MM = 4.0
RECIPIENT_LINE_AFTER_MM = 4.0

# ìŠ¤í‹°ì»¤ ìš©ì§€ ì„¤ì • (21Ã—29.5cm / 65ì¹¸ / 3.82Ã—2.11cm)
STICKER_COLS = 5
STICKER_ROWS = 13
STICKER_PER_PAGE = STICKER_COLS * STICKER_ROWS  # 65

# ìš©ì§€ í¬ê¸° (mm)  -> 21Ã—29.5cm
STICKER_PAGE_W_MM = 210.0
STICKER_PAGE_H_MM = 295.0

# ì‚¬ìš©ì ì§€ì • ì—¬ë°± (cm -> mm)
STICKER_MARGIN_LEFT_MM = 4.0
STICKER_MARGIN_RIGHT_MM = 4.0
STICKER_MARGIN_TOP_MM = 11.0
STICKER_MARGIN_BOTTOM_MM = 10.0

# ìŠ¤í‹°ì»¤(ë¼ë²¨) í¬ê¸° (mm) -> 3.82Ã—2.11cm
STICKER_CELL_W_MM = 38.2
STICKER_CELL_H_MM = 21.1

# ìŠ¤í‹°ì»¤ ê°„ê²©: ìƒ/í•˜ 0cm, ì¢Œ/ìš° 0.3cm
# âš ï¸ ë‹¤ë§Œ "ìš©ì§€(21cm) - ì—¬ë°±(0.4cm*2)" í­ ì•ˆì— 5ì¹¸ì„ ë§ì¶”ê¸° ìœ„í•´,
#     ê°€ë¡œ ê°„ê²©ì€ í•„ìš” ì‹œ 0.3cmë³´ë‹¤ ì•„ì£¼ ì¡°ê¸ˆ(â‰ˆ0.025cm) ì¤„ì–´ë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
STICKER_GAP_X_MM = 3.0
STICKER_GAP_Y_MM = 0.0

# ê¸€ì
STICKER_FONT_SIZE = 13
STICKER_LEADING = 16

# í”„ë¦°í„° ì¶œë ¥ ë³´ì •(í•„ìš” ì‹œ ìˆ˜ë™ ì¡°ì •, ê¸°ë³¸ 0)
STICKER_OFFSET_X_MM = 0.0
STICKER_OFFSET_Y_MM = 0.0

# âœ… í–‰ë³„ í…ìŠ¤íŠ¸ ìœ„ì¹˜ ë¯¸ì„¸ë³´ì •
# - 1~5í–‰(ìƒë‹¨ 5ì¤„): ìƒí’ˆëª… ìœ„ì¹˜ë¥¼ "ì¡°ê¸ˆ ë” ìœ„ë¡œ"
# - 12~13í–‰(í•˜ë‹¨ 2ì¤„): ìƒí’ˆëª… ìœ„ì¹˜ë¥¼ "ì¡°ê¸ˆ ë” ì•„ë˜ë¡œ"
# (ë‹¨ìœ„: mm, í•„ìš”í•˜ë©´ ìˆ«ìë§Œ ì¡°ì ˆí•˜ë©´ ë©ë‹ˆë‹¤)
STICKER_TEXT_SHIFT_TOP_ROWS_MM = 0.8
STICKER_TEXT_SHIFT_BOTTOM_ROWS_MM = 0.8


def _clean_access_message(msg: str) -> str:
    s = str(msg or "").strip()
    return s if s else TC_ACCESS_FALLBACK


# -------------------- âœ… TC Settings (persist) --------------------
def load_tc_settings() -> Dict[str, str]:
    default = {"dawn": TC_TYPE_DAWN_DEFAULT, "next": TC_TYPE_NEXT_DEFAULT}
    if not TC_SETTINGS_PATH.exists():
        return default
    try:
        data = json.loads(TC_SETTINGS_PATH.read_text(encoding="utf-8"))
        if not isinstance(data, dict):
            return default
        dawn = normalize_text(data.get("dawn", "")) or TC_TYPE_DAWN_DEFAULT
        nxt = normalize_text(data.get("next", "")) or TC_TYPE_NEXT_DEFAULT
        return {"dawn": dawn, "next": nxt}
    except Exception:
        return default


def save_tc_settings(dawn: str, nxt: str) -> None:
    dawn = normalize_text(dawn) or TC_TYPE_DAWN_DEFAULT
    nxt = normalize_text(nxt) or TC_TYPE_NEXT_DEFAULT
    TC_SETTINGS_PATH.write_text(
        json.dumps({"dawn": dawn, "next": nxt}, ensure_ascii=False, indent=2),
        encoding="utf-8",
    )


# -------------------- í‘œí˜„ê·œì¹™ (í†µ/ê°œ/íŒ©/ë´‰ ê°™ì€ ë‹¨ìœ„ ê´€ë¦¬) --------------------
def default_expression_rules() -> Dict:
    return {
        "default_unit": "ê°œ",
        "units": [
            {"enabled": True, "unit": "ê°œ"},
            {"enabled": True, "unit": "ë´‰"},
            {"enabled": True, "unit": "í†µ"},
            {"enabled": True, "unit": "íŒ©"},
        ],
        "note": "í•©ì‚°ê·œì¹™(N)ì´ ì ìš©ë  ë‹¨ìœ„ë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤.",
    }


def save_expression_rules(data: Dict) -> None:
    EXPR_RULES_PATH.write_text(json.dumps(data, ensure_ascii=False, indent=2), encoding="utf-8")


def load_expression_rules() -> Dict:
    if not EXPR_RULES_PATH.exists():
        data = default_expression_rules()
        save_expression_rules(data)
        return data
    try:
        data = json.loads(EXPR_RULES_PATH.read_text(encoding="utf-8"))
        if not isinstance(data, dict):
            raise ValueError("invalid")

        if "units" not in data or not isinstance(data["units"], list):
            data["units"] = default_expression_rules()["units"]

        if "default_unit" not in data or not isinstance(data["default_unit"], str):
            data["default_unit"] = default_expression_rules()["default_unit"]

        cleaned_units = []
        for r in data["units"]:
            u = normalize_text(r.get("unit", ""))
            if not u:
                continue
            cleaned_units.append({"enabled": bool(r.get("enabled", True)), "unit": u})
        data["units"] = cleaned_units
        data["default_unit"] = normalize_text(data.get("default_unit", "ê°œ")) or "ê°œ"
        return data
    except Exception:
        data = default_expression_rules()
        save_expression_rules(data)
        return data


def get_bundle_units(expr: Dict) -> List[str]:
    units = []
    for r in expr.get("units", []):
        if r.get("enabled", True):
            u = normalize_text(r.get("unit", ""))
            if u:
                units.append(u)

    seen = set()
    out = []
    for u in units:
        if u not in seen:
            out.append(u)
            seen.add(u)
    return out


def build_bundle_re(bundle_units: List[str]) -> re.Pattern:
    if not bundle_units:
        bundle_units = ["ê°œ"]
    unit_alt = "|".join(map(re.escape, bundle_units))
    return re.compile(rf"^\s*(\d+)\s*({unit_alt})\s*$")


# -------------------- ìƒí’ˆëª… ë§¤ì¹­ ê·œì¹™ (í•©ì‚°ê·œì¹™ N í¬í•¨) --------------------
def default_mapping_rules() -> List[Dict]:
    return [
        {
            "enabled": True,
            "match_type": "contains",
            "pattern": "ì™€ì¼ë“œë£¨ê¼´ë¼",
            "display_name": "ì™€ì¼ë“œ",
            "sum_rule": None,
            "note": 'ì˜ˆ) "ì±„ì†ŒíŒœ ì™€ì¼ë“œë£¨ê¼´ë¼ 1kg ..." -> ì™€ì¼ë“œ',
        },
        {
            "enabled": True,
            "match_type": "contains",
            "pattern": "ë¼ë””ì¹˜ì˜¤",
            "display_name": "ë¼ë””ì¹˜ì˜¤",
            "sum_rule": None,
            "note": 'ì˜ˆ) "ì±„ì†ŒíŒœ ë¼ë””ì¹˜ì˜¤ 1í†µ ..." -> ë¼ë””ì¹˜ì˜¤',
        },
        {
            "enabled": False,
            "match_type": "contains",
            "pattern": "ì˜¤ë Œì§€",
            "display_name": "ì˜¤ë Œì§€",
            "sum_rule": 5,
            "note": "ì˜ˆ) ì˜¤ë Œì§€ í•©ì‚°ê·œì¹™=5",
        },
    ]


def save_mapping_rules(rules: List[Dict]) -> None:
    MAPPING_PATH.write_text(json.dumps(rules, ensure_ascii=False, indent=2), encoding="utf-8")


def load_mapping_rules() -> List[Dict]:
    if not MAPPING_PATH.exists():
        rules = default_mapping_rules()
        save_mapping_rules(rules)
        return rules

    try:
        raw = json.loads(MAPPING_PATH.read_text(encoding="utf-8"))
        if isinstance(raw, list):
            cleaned = []
            for r in raw:
                sr = _safe_int(r.get("sum_rule"))
                if sr is not None and sr < 2:
                    sr = None
                cleaned.append(
                    dict(
                        enabled=bool(r.get("enabled", True)),
                        match_type=normalize_text(r.get("match_type", "contains")) or "contains",
                        pattern=normalize_text(r.get("pattern", "")),
                        display_name=normalize_text(r.get("display_name", "")),
                        sum_rule=sr,
                        note=normalize_text(r.get("note", "")),
                    )
                )
            return cleaned
    except Exception:
        pass

    rules = default_mapping_rules()
    save_mapping_rules(rules)
    return rules


def apply_mapping(actual_name: str, rules: List[Dict]) -> Tuple[str, bool, Optional[int]]:
    actual = normalize_text(actual_name)
    if not actual:
        return "", False, None

    for r in rules:
        if not r.get("enabled", True):
            continue

        mt = normalize_text(r.get("match_type", "contains")) or "contains"
        pattern = normalize_text(r.get("pattern", ""))
        display = normalize_text(r.get("display_name", ""))
        sr = _safe_int(r.get("sum_rule"))

        if not pattern or not display:
            continue

        matched = False
        if mt == "exact":
            matched = (actual == pattern)
        elif mt == "contains":
            matched = (pattern in actual)
        elif mt == "regex":
            try:
                matched = bool(re.search(pattern, actual))
            except re.error:
                matched = False

        if matched:
            if sr is not None and sr < 2:
                sr = None
            return display, True, sr

    # fallback
    s = re.sub(r"^\s*ì±„ì†ŒíŒœ\s*", "", actual)
    s = re.sub(r"\([^)]*\)", "", s).strip()
    s = re.sub(r"\s+", " ", s).strip()
    m = UNIT_RE.search(s)
    if m:
        s = s[: m.start()].strip()

    toks = s.split()
    if not toks:
        return actual, False, None

    PREFIX = {"ìƒ", "ìœ ê¸°ë†", "êµ­ì‚°", "ìˆ˜ì…", "ëƒ‰ë™", "ë² ì´ë¹„", "í”„ë¦¬ë¯¸ì—„"}
    if len(toks) >= 2 and toks[0] in PREFIX:
        fallback = toks[0] + toks[1]
    else:
        fallback = toks[0]

    return fallback, False, None


def mapping_df_from_list(rules: List[Dict]) -> pd.DataFrame:
    df = pd.DataFrame(rules)
    keep = ["enabled", "match_type", "pattern", "display_name", "sum_rule", "note"]
    for c in keep:
        if c not in df.columns:
            df[c] = None
    return df[keep]


def mapping_list_from_df(edited: pd.DataFrame) -> List[Dict]:
    cleaned = []
    for _, row in edited.iterrows():
        pattern = normalize_text(row.get("pattern"))
        display = normalize_text(row.get("display_name"))
        if not pattern or not display:
            continue

        mt = normalize_text(row.get("match_type")) or "contains"
        if mt not in {"contains", "exact", "regex"}:
            mt = "contains"

        sr = _safe_int(row.get("sum_rule"))
        if sr is not None and sr < 2:
            sr = None

        cleaned.append(
            dict(
                enabled=bool(row.get("enabled", True)),
                match_type=mt,
                pattern=pattern,
                display_name=display,
                sum_rule=sr,
                note=normalize_text(row.get("note")),
            )
        )
    return cleaned


# -------------------- Backups (Excel) --------------------
def backup_rules_to_excel(mapping_rules: List[Dict], expr_rules: Dict) -> Path:
    out_path = BACKUP_DIR / "ìƒí’ˆë³„ë§¤ì¹­ê·œì¹™_ë°±ì—….xlsx"

    df_map = mapping_df_from_list(mapping_rules).rename(
        columns={
            "enabled": "ì‚¬ìš©",
            "match_type": "ë§¤ì¹­ë°©ì‹",
            "pattern": "ì‹¤ì œìƒí’ˆëª…(íŒ¨í„´)",
            "display_name": "í‘œì‹œë ìƒí’ˆëª…",
            "sum_rule": "í•©ì‚°ê·œì¹™(N)",
            "note": "ë©”ëª¨",
        }
    )

    units = expr_rules.get("units", [])
    df_expr = pd.DataFrame(units)
    if df_expr.empty:
        df_expr = pd.DataFrame([{"enabled": True, "unit": expr_rules.get("default_unit", "ê°œ")}])
    if "enabled" not in df_expr.columns:
        df_expr["enabled"] = True
    if "unit" not in df_expr.columns:
        df_expr["unit"] = ""
    df_expr = df_expr[["enabled", "unit"]].rename(columns={"enabled": "ì‚¬ìš©", "unit": "ë‹¨ìœ„"})

    df_meta = pd.DataFrame(
        [
            {"í‚¤": "default_unit", "ê°’": expr_rules.get("default_unit", "ê°œ")},
            {"í‚¤": "note", "ê°’": expr_rules.get("note", "")},
        ]
    )

    with pd.ExcelWriter(out_path, engine="openpyxl") as writer:
        df_map.to_excel(writer, sheet_name="ìƒí’ˆëª…ë§¤ì¹­", index=False)
        df_expr.to_excel(writer, sheet_name="í‘œí˜„ê·œì¹™_ë‹¨ìœ„", index=False)
        df_meta.to_excel(writer, sheet_name="í‘œí˜„ê·œì¹™_ì„¤ì •", index=False)

    return out_path


# -------------------- Sidebar panels (ë§¤ì¹­ ê·œì¹™ í˜ì´ì§€ì—ì„œë§Œ) --------------------
def sidebar_backup_folder():
    with st.sidebar.expander("ğŸ“ ê·œì¹™ ë°±ì—…í´ë”", expanded=False):
        try:
            backups = sorted(BACKUP_DIR.glob("*.xlsx"), key=lambda p: p.stat().st_mtime, reverse=True)
        except Exception:
            backups = []

        if not backups:
            st.caption("ì•„ì§ ë°±ì—… íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return

        for i, fp in enumerate(backups[:60]):
            cols = st.columns([6, 2, 2])
            cols[0].write(fp.name)

            try:
                b = fp.read_bytes()
                cols[1].download_button(
                    "ë‹¤ìš´",
                    data=b,
                    file_name=fp.name,
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    key=f"dl_bk_{i}_{fp.name}",
                    use_container_width=True,
                )
            except Exception:
                cols[1].write("")

            if cols[2].button("ì‚­ì œ", key=f"rm_bk_{i}_{fp.name}", use_container_width=True):
                try:
                    fp.unlink()
                    st.success(f"ì‚­ì œ ì™„ë£Œ: {fp.name}")
                    st.rerun()
                except Exception:
                    st.error("ì‚­ì œ ì‹¤íŒ¨")


def sidebar_expression_rules():
    expr = load_expression_rules()
    units = expr.get("units", [])
    default_unit = normalize_text(expr.get("default_unit", "ê°œ")) or "ê°œ"

    with st.sidebar.expander("âš™ï¸ í‘œí˜„ê·œì¹™", expanded=False):
        st.caption("í•©ì‚°ê·œì¹™(N)ì„ ì ìš©í•  ë‹¨ìœ„ë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤. (í†µ/ê°œ/íŒ©/ë´‰ ë“±)")

        df = pd.DataFrame(units)
        if df.empty:
            df = pd.DataFrame([{"enabled": True, "unit": default_unit}])
        if "enabled" not in df.columns:
            df["enabled"] = True
        if "unit" not in df.columns:
            df["unit"] = ""
        df = df[["enabled", "unit"]]

        edited = st.data_editor(
            df,
            hide_index=True,
            num_rows="dynamic",
            use_container_width=True,
            column_config={
                "enabled": st.column_config.CheckboxColumn("ì‚¬ìš©", default=True),
                "unit": st.column_config.TextColumn("ë‹¨ìœ„"),
            },
            key="expr_units_editor",
        )

        enabled_units = []
        for _, r in edited.iterrows():
            u = normalize_text(r.get("unit", ""))
            if u:
                enabled_units.append((bool(r.get("enabled", True)), u))

        enabled_only = [u for en, u in enabled_units if en]
        if not enabled_only:
            enabled_only = ["ê°œ"]

        if default_unit not in enabled_only:
            default_unit = enabled_only[0]

        new_default = st.selectbox(
            "ê¸°ë³¸ë‹¨ìœ„ (êµ¬ë¶„ì´ ë¹„ì–´ìˆì„ ë•Œ)",
            options=enabled_only,
            index=enabled_only.index(default_unit) if default_unit in enabled_only else 0,
            key="expr_default_unit",
        )

        if st.button("ğŸ’¾ í‘œí˜„ê·œì¹™ ì €ì¥", use_container_width=True, key="save_expr_rules_btn"):
            cleaned_units = []
            seen = set()
            for en, u in enabled_units:
                if u in seen:
                    continue
                cleaned_units.append({"enabled": bool(en), "unit": u})
                seen.add(u)

            data = {
                "default_unit": new_default,
                "units": cleaned_units,
                "note": expr.get("note", ""),
            }
            save_expression_rules(data)
            st.success("í‘œí˜„ê·œì¹™ ì €ì¥ ì™„ë£Œ")
            st.rerun()


# -------------------- Excel decrypt / read --------------------
def decrypt_excel(uploaded_bytes: bytes, password: str = EXCEL_PASSWORD) -> io.BytesIO:
    if msoffcrypto is None:
        raise ModuleNotFoundError("msoffcrypto not installed")
    decrypted = io.BytesIO()
    office = msoffcrypto.OfficeFile(io.BytesIO(uploaded_bytes))
    office.load_key(password=password)
    office.decrypt(decrypted)
    decrypted.seek(0)
    return decrypted


def _norm_col(x) -> str:
    s = str(x if x is not None else "")
    s = s.replace("\xa0", " ").replace("\n", " ").replace("\r", " ")
    return normalize_text(s)


def find_col(df: pd.DataFrame, keywords: List[str]) -> Optional[str]:
    """ì»¬ëŸ¼ëª… íƒìƒ‰: ê³µë°±/ê°œí–‰/NBSP ë“±ì„ ì •ê·œí™”í•´ì„œ ë§¤ì¹­í•©ë‹ˆë‹¤."""
    cols = list(df.columns)
    if not cols:
        return None

    kw_norm = [_norm_col(k) for k in (keywords or []) if _norm_col(k)]
    if not kw_norm:
        return None

    col_norm = [_norm_col(c) for c in cols]

    # 1) ì •ê·œí™” í›„ ì™„ì „ì¼ì¹˜
    for k in kw_norm:
        for c, cn in zip(cols, col_norm):
            if k == cn:
                return c

    # 2) ì •ê·œí™” í›„ ë¶€ë¶„ì¼ì¹˜
    for c, cn in zip(cols, col_norm):
        for k in kw_norm:
            if k in cn:
                return c

    return None


# -------------------- Smart Excel header detection --------------------
REQUIRED_COL_GROUPS = OrderedDict(
    [
        ("ìƒí’ˆëª…", ["ìƒí’ˆëª…", "ìƒí’ˆ", "ì œí’ˆëª…"]),
        ("ìˆ˜ëŸ‰", ["ìˆ˜ëŸ‰", "ì£¼ë¬¸ìˆ˜ëŸ‰", "êµ¬ë§¤ìˆ˜ëŸ‰", "ê°œìˆ˜"]),
        ("êµ¬ë§¤ìëª…", ["êµ¬ë§¤ìëª…", "êµ¬ë§¤ì"]),
        ("ìˆ˜ì·¨ì¸ëª…", ["ìˆ˜ì·¨ì¸ëª…", "ìˆ˜ë ¹ì¸", "ë°›ëŠ”ì‚¬ëŒ"]),
        ("í†µí•©ë°°ì†¡ì§€", ["í†µí•©ë°°ì†¡ì§€", "ë°°ì†¡ì§€", "ì£¼ì†Œ"]),
        ("ì˜µì…˜ì •ë³´", ["ì˜µì…˜ì •ë³´", "ì˜µì…˜", "ì„ íƒì˜µì…˜"]),
        ("ìˆ˜ì·¨ì¸ì—°ë½ì²˜", ["ìˆ˜ì·¨ì¸ì—°ë½ì²˜", "ìˆ˜ë ¹ì¸ì—°ë½ì²˜", "ìˆ˜ì·¨ì¸ ì—°ë½ì²˜", "ìˆ˜ë ¹ì¸ ì—°ë½ì²˜", "ì „í™”ë²ˆí˜¸", "ì—°ë½ì²˜"]),
        ("ë°°ì†¡ë©”ì„¸ì§€", ["ë°°ì†¡ë©”ì„¸ì§€", "ë°°ì†¡ë©”ì‹œì§€", "ë°°ì†¡ ë©”ì‹œì§€", "ë°°ì†¡ ë©”ì„¸ì§€", "ë°°ì†¡ìš”ì²­ì‚¬í•­", "ìš”ì²­ì‚¬í•­"]),
    ]
)


# -------------------- âœ… Sticker Exclude Settings (persist) --------------------
def load_sticker_exclude() -> List[str]:
    """ìŠ¤í‹°ì»¤ìš©ì§€ PDFì—ì„œ ì œì™¸í•  ìƒí’ˆëª… ëª©ë¡ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    if not STICKER_SETTINGS_PATH.exists():
        return []
    try:
        data = json.loads(STICKER_SETTINGS_PATH.read_text(encoding="utf-8"))
        # allow either list or {"exclude":[...]}
        if isinstance(data, dict):
            data = data.get("exclude", [])
        if not isinstance(data, list):
            return []
        out: List[str] = []
        seen = set()
        for x in data:
            s = normalize_text(x)
            if not s:
                continue
            if s in seen:
                continue
            out.append(s)
            seen.add(s)
        return out
    except Exception:
        return []


def save_sticker_exclude(exclude: List[str]) -> None:
    exclude = exclude or []
    out: List[str] = []
    seen = set()
    for x in exclude:
        s = normalize_text(x)
        if not s:
            continue
        if s in seen:
            continue
        out.append(s)
        seen.add(s)
    STICKER_SETTINGS_PATH.write_text(
        json.dumps({"exclude": out}, ensure_ascii=False, indent=2),
        encoding="utf-8",
    )



def _missing_required_cols(df: pd.DataFrame) -> List[str]:
    missing = []
    for k, kws in REQUIRED_COL_GROUPS.items():
        if find_col(df, kws) is None:
            missing.append(k)
    return missing


def _guess_header_row(preview: pd.DataFrame, scan_limit: int = 40) -> Tuple[Optional[int], int]:
    """header=None ë¡œ ì½ì€ previewì—ì„œ 'í—¤ë”ë¡œ ë³´ì´ëŠ” í–‰'ì„ ì¶”ì •"""
    if preview is None or preview.empty:
        return None, 0

    best_i = None
    best_score = -1

    n = min(scan_limit, len(preview))
    for i in range(n):
        row = preview.iloc[i].tolist()
        row_strs = []
        for v in row:
            if v is None or (isinstance(v, float) and pd.isna(v)):
                continue
            s = _norm_col(v)
            if s:
                row_strs.append(s)

        if not row_strs:
            continue

        score = 0
        for _, kws in REQUIRED_COL_GROUPS.items():
            hit = False
            for kw in kws:
                kw_n = _norm_col(kw)
                if not kw_n:
                    continue
                if any(kw_n in cell for cell in row_strs):
                    hit = True
                    break
            if hit:
                score += 1

        if score > best_score:
            best_score = score
            best_i = i

    return best_i, max(best_score, 0)


def smart_read_orders_excel(excel_bytes: bytes, min_score: int = 4) -> Tuple[pd.DataFrame, Dict]:
    """
    ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´/ì¼ê´„ë°œì†¡ ì—‘ì…€ì²˜ëŸ¼ ìƒë‹¨ì— ì•ˆë‚´ë¬¸ì´ ìˆëŠ” ê²½ìš°,
    'í—¤ë” í–‰'ì„ ìë™ìœ¼ë¡œ ì°¾ì•„ì„œ DataFrameì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    if not excel_bytes:
        raise ValueError("empty excel bytes")

    def _read(sheet, header, nrows=None):
        bio = io.BytesIO(excel_bytes)
        bio.seek(0)
        return pd.read_excel(bio, sheet_name=sheet, header=header, nrows=nrows, engine="openpyxl")

    bio0 = io.BytesIO(excel_bytes)
    bio0.seek(0)
    xls = pd.ExcelFile(bio0, engine="openpyxl")

    best_fallback = None  # (df, meta)

    for sheet in xls.sheet_names:
        # 1) ì¼ë°˜ header=0 ì‹œë„
        try:
            df0 = _read(sheet, header=0)
            df0 = df0.dropna(how="all")
            missing0 = _missing_required_cols(df0)
            if not missing0:
                return df0, {"sheet": sheet, "header_row": 0, "method": "header=0"}
            if best_fallback is None:
                best_fallback = (df0, {"sheet": sheet, "header_row": 0, "method": "header=0", "missing": missing0})
        except Exception:
            pass

        # 2) header í–‰ ì¶”ì •
        try:
            preview = _read(sheet, header=None, nrows=60)
            header_row, score = _guess_header_row(preview, scan_limit=40)

            if header_row is None or score < min_score:
                continue

            df = _read(sheet, header=int(header_row))
            df = df.dropna(how="all")

            # ë¹ˆ ì»¬ëŸ¼ ì œê±°(Unnamed: n)
            try:
                df = df.loc[:, ~df.columns.astype(str).str.match(r"^Unnamed")]
            except Exception:
                pass

            missing = _missing_required_cols(df)
            if not missing:
                return df, {"sheet": sheet, "header_row": int(header_row), "method": f"guessed(score={score})"}

            if best_fallback is None:
                best_fallback = (
                    df,
                    {"sheet": sheet, "header_row": int(header_row), "method": f"guessed(score={score})", "missing": missing},
                )
        except Exception:
            pass

    if best_fallback is not None:
        return best_fallback

    df_last = _read(0, header=0)
    return df_last, {"sheet": 0, "header_row": 0, "method": "fallback"}


# -------------------- í•©ì‚°ê·œì¹™ ì ìš© (í‘œí˜„ê·œì¹™ì—ì„œ ì¼  ë‹¨ìœ„ì—ë§Œ) --------------------
def parse_bundle_variant(variant: str, bundle_re: re.Pattern) -> Tuple[Optional[int], Optional[str]]:
    m = bundle_re.match((variant or "").strip())
    if not m:
        return None, None
    try:
        return int(m.group(1)), m.group(2)
    except Exception:
        return None, None


def explode_sum_rule_rows(
    df_rows: pd.DataFrame,
    bundle_units: List[str],
    default_unit: str,
) -> pd.DataFrame:
    bundle_units = bundle_units or [default_unit or "ê°œ"]
    default_unit = default_unit or "ê°œ"
    bundle_re = build_bundle_re(bundle_units)
    unit_set = set(bundle_units)

    out = []
    for _, r in df_rows.iterrows():
        product = r["ì œí’ˆëª…"]
        variant = (r.get("êµ¬ë¶„", "") or "").strip()
        qty = r.get("ìˆ˜ëŸ‰", None)
        rule_n = _safe_int(r.get("í•©ì‚°ê·œì¹™", None))

        if rule_n is None or rule_n < 2:
            out.append({"ì œí’ˆëª…": product, "êµ¬ë¶„": variant, "ìˆ˜ëŸ‰": qty})
            continue

        # êµ¬ë¶„ì´ ë¹„ì–´ ìˆìœ¼ë©´ ê¸°ë³¸ ë‹¨ìœ„ 1ê°œë¡œ ê°„ì£¼
        if variant == "":
            unit_size, unit_label = 1, default_unit
            is_bundle = unit_label in unit_set
        else:
            unit_size, unit_label = parse_bundle_variant(variant, bundle_re)
            is_bundle = (unit_size is not None and unit_label in unit_set)

        if not is_bundle:
            out.append({"ì œí’ˆëª…": product, "êµ¬ë¶„": variant, "ìˆ˜ëŸ‰": qty})
            continue

        try:
            total_units = int(round(float(qty))) * int(unit_size)
        except Exception:
            out.append({"ì œí’ˆëª…": product, "êµ¬ë¶„": variant, "ìˆ˜ëŸ‰": qty})
            continue

        if total_units <= 0:
            continue

        full = total_units // rule_n
        rem = total_units % rule_n

        if full > 0:
            out.append({"ì œí’ˆëª…": product, "êµ¬ë¶„": f"{rule_n}{unit_label}", "ìˆ˜ëŸ‰": full})
        if rem > 0:
            out.append({"ì œí’ˆëª…": product, "êµ¬ë¶„": f"{rem}{unit_label}", "ìˆ˜ëŸ‰": 1})

    return pd.DataFrame(out)


# -------------------- ë°°ì†¡ ì˜µì…˜ ë¶„ë¥˜ & ê·¸ë£¹ ê·œì¹™ (ìƒˆë²½ ìš°ì„ ) --------------------
def classify_delivery(opt: str) -> str:
    s = str(opt or "")
    if "ìƒˆë²½ë°°ì†¡" in s:
        return "ìƒˆë²½ë°°ì†¡"
    if "ìµì¼ë°°ì†¡" in s:
        return "ìµì¼ë°°ì†¡"
    return "ê¸°íƒ€"


def decide_group_delivery(deliv_set: set) -> str:
    if "ìƒˆë²½ë°°ì†¡" in deliv_set:
        return "ìƒˆë²½ë°°ì†¡"
    if "ìµì¼ë°°ì†¡" in deliv_set:
        return "ìµì¼ë°°ì†¡"
    return "ê¸°íƒ€"


# -------------------- PDF 1) ì œí’ˆë³„ ê°œìˆ˜ --------------------
def build_summary_pdf(summary_df: pd.DataFrame) -> bytes:
    buf = io.BytesIO()

    font_name = "Helvetica"
    try:
        pdfmetrics.registerFont(UnicodeCIDFont("HYGothic-Medium"))
        font_name = "HYGothic-Medium"
    except Exception:
        pass

    doc = SimpleDocTemplate(
        buf,
        pagesize=A4,
        leftMargin=15 * mm,
        rightMargin=15 * mm,
        topMargin=15 * mm,
        bottomMargin=15 * mm,
    )

    styles = getSampleStyleSheet()
    title_style = ParagraphStyle(
        "title",
        parent=styles["Heading2"],
        fontName=font_name,
        fontSize=14,
        leading=18,
        spaceAfter=8,
    )

    elems = []
    elems.append(Paragraph("â–£ ì œí’ˆë³„ ê°œìˆ˜", title_style))
    elems.append(Spacer(1, 4))

    data = [["ì œí’ˆëª…", "êµ¬ë¶„", "ìˆ˜ëŸ‰"]]
    for _, row in summary_df.iterrows():
        data.append([str(row["ì œí’ˆëª…"]), str(row["êµ¬ë¶„"]), str(row["ìˆ˜ëŸ‰"])])

    table = LongTable(
        data,
        colWidths=[75 * mm, 60 * mm, 25 * mm],
        repeatRows=1,
    )
    table.setStyle(
        TableStyle(
            [
                ("FONTNAME", (0, 0), (-1, -1), font_name),
                ("FONTSIZE", (0, 0), (-1, -1), 10),
                ("BACKGROUND", (0, 0), (-1, 0), colors.whitesmoke),
                ("ALIGN", (0, 0), (-1, 0), "CENTER"),
                ("ALIGN", (2, 1), (2, -1), "RIGHT"),
                ("GRID", (0, 0), (-1, -1), 0.25, colors.grey),
                ("TOPPADDING", (0, 0), (-1, 0), 6),
                ("BOTTOMPADDING", (0, 0), (-1, 0), 6),
                ("TOPPADDING", (0, 1), (-1, -1), 4),
                ("BOTTOMPADDING", (0, 1), (-1, -1), 4),
            ]
        )
    )

    elems.append(table)
    doc.build(elems)
    return buf.getvalue()


# -------------------- PDF 2) ìˆ˜ì·¨ì¸ë³„ ì¶œë ¥ --------------------
def build_recipient_pdf(entries: List[Dict[str, str]]) -> bytes:
    buf = io.BytesIO()

    font_name = "Helvetica"
    try:
        pdfmetrics.registerFont(UnicodeCIDFont("HYGothic-Medium"))
        font_name = "HYGothic-Medium"
    except Exception:
        pass

    left_margin = 12 * mm
    right_margin = 12 * mm
    top_margin = 12 * mm
    bottom_margin = 12 * mm

    doc = SimpleDocTemplate(
        buf,
        pagesize=A4,
        leftMargin=left_margin,
        rightMargin=right_margin,
        topMargin=top_margin,
        bottomMargin=bottom_margin,
    )

    styles = getSampleStyleSheet()
    base_style = ParagraphStyle(
        "base",
        parent=styles["Normal"],
        fontName=font_name,
        fontSize=RECIPIENT_FONT_SIZE,
        leading=RECIPIENT_LEADING,
        spaceAfter=0,
    )

    usable_width = A4[0] - left_margin - right_margin

    elems = []
    for e in entries:
        recv = (e.get("ìˆ˜ì·¨ì¸ëª…") or "").strip() or " "
        items = (e.get("items_line") or "").strip() or " "

        name_token_plain = f"{recv} - "
        indent = _text_width_pt(name_token_plain, font_name, base_style.fontSize)
        indent_cap = usable_width * 0.55
        indent = min(max(indent, 40), indent_cap)

        line_style = ParagraphStyle(
            f"line_{abs(hash(recv)) % 10_000_000}",
            parent=base_style,
            leftIndent=indent,
            firstLineIndent=-indent,
        )

        text = f"<b>{_xml_escape(recv)}</b> - {_xml_escape(items)}"
        p = Paragraph(text, line_style)

        block = KeepTogether(
            [
                p,
                Spacer(1, RECIPIENT_BLOCK_GAP_MM * mm),
                HRFlowable(
                    width="100%",
                    thickness=0.4,
                    color=colors.lightgrey,
                    spaceBefore=0,
                    spaceAfter=RECIPIENT_LINE_AFTER_MM * mm,
                ),
            ]
        )
        elems.append(block)

    doc.build(elems)
    return buf.getvalue()


# -------------------- PDF 3) ìŠ¤í‹°ì»¤ ìš©ì§€ --------------------
def _wrap_for_cell(txt: str, font_name: str, font_size: int, max_w_pt: float) -> List[str]:
    txt = (txt or "").strip()
    if not txt:
        return [""]

    def w(s: str) -> float:
        return _text_width_pt(s, font_name, font_size)

    if w(txt) <= max_w_pt:
        return [txt]

    if " " in txt:
        parts = txt.split()
        line1 = ""
        consumed = 0
        for p in parts:
            cand = (line1 + " " + p).strip()
            if w(cand) <= max_w_pt:
                line1 = cand
                consumed += 1
            else:
                break
        rest = " ".join(parts[consumed:]).strip()
        if not rest:
            return [line1]
        if w(rest) <= max_w_pt:
            return [line1, rest]
        trimmed = rest
        while trimmed and w(trimmed + "...") > max_w_pt:
            trimmed = trimmed[:-1]
        return [line1, (trimmed + "...") if trimmed else "..."]

    line1 = ""
    for ch in txt:
        if w(line1 + ch) <= max_w_pt:
            line1 += ch
        else:
            break
    rest = txt[len(line1):].strip()
    if not rest:
        return [line1]
    if w(rest) <= max_w_pt:
        return [line1, rest]
    trimmed = rest
    while trimmed and w(trimmed + "...") > max_w_pt:
        trimmed = trimmed[:-1]
    return [line1, (trimmed + "...") if trimmed else "..."]


def _draw_center_text(c: canvas.Canvas, font_name: str, font_size: int, x_center: float, y: float, txt: str):
    txt = (txt or "").strip()
    if not txt:
        return
    w = _text_width_pt(txt, font_name, font_size)
    x_left = x_center - (w / 2.0)
    t = c.beginText()
    t.setTextOrigin(x_left, y)
    t.setFont(font_name, font_size)
    t.textOut(txt)
    c.drawText(t)


def build_sticker_pdf(label_texts: List[str]) -> bytes:
    """
    ìŠ¤í‹°ì»¤(ë¼ë²¨) PDF ì¶œë ¥
    - ìš©ì§€: 21Ã—29.5cm
    - ì—¬ë°±: L/R 0.4cm, T 1.1cm, B 1.0cm
    - ë¼ë²¨: 3.82Ã—2.11cm, 5Ã—13 = 65ì¹¸
    - ê°„ê²©: ì¢Œ/ìš° 0.3cm, ìƒ/í•˜ 0cm (í­/ì—¬ë°±ì„ ë§ì¶”ê¸° ìœ„í•´ ê°€ë¡œ ê°„ê²©ì€ ìë™ ë³´ì •ë  ìˆ˜ ìˆìŒ)
    - ê° ë¼ë²¨ ì¤‘ì•™ì— ìƒí’ˆëª…(í…ìŠ¤íŠ¸) ì¶œë ¥
    """
    buf = io.BytesIO()

    font_name = "Helvetica"
    try:
        pdfmetrics.registerFont(UnicodeCIDFont("HYGothic-Medium"))
        font_name = "HYGothic-Medium"
    except Exception:
        pass

    pagesize = (STICKER_PAGE_W_MM * mm, STICKER_PAGE_H_MM * mm)
    c = canvas.Canvas(buf, pagesize=pagesize)
    page_w_pt, page_h_pt = pagesize

    left_pt = STICKER_MARGIN_LEFT_MM * mm
    right_pt = STICKER_MARGIN_RIGHT_MM * mm
    top_pt = STICKER_MARGIN_TOP_MM * mm
    bottom_pt = STICKER_MARGIN_BOTTOM_MM * mm

    cell_w_pt = STICKER_CELL_W_MM * mm
    cell_h_pt = STICKER_CELL_H_MM * mm

    # gap (ê°€ë¡œëŠ” "0.3cm" ëª©í‘œì´ì§€ë§Œ, ì‹¤ì œ í­/ì—¬ë°±ì— ë§ì¶”ê¸° ìœ„í•´ ìë™ ë³´ì •)
    gap_x_target_pt = STICKER_GAP_X_MM * mm
    gap_y_target_pt = STICKER_GAP_Y_MM * mm

    usable_w = page_w_pt - left_pt - right_pt
    usable_h = page_h_pt - top_pt - bottom_pt

    # ê°€ë¡œ ê°„ê²© ìë™ ë³´ì •(ê·¸ë¦¬ë“œê°€ ì—¬ë°±ì„ ì¹¨ë²”í•˜ë©´ gapì„ ì¤„ì—¬ì„œ ë§ì¶¤)
    if STICKER_COLS > 1:
        grid_w_target = (STICKER_COLS * cell_w_pt) + ((STICKER_COLS - 1) * gap_x_target_pt)
        if grid_w_target > usable_w + (0.1 * mm):
            gap_x_pt = max(0.0, (usable_w - (STICKER_COLS * cell_w_pt)) / (STICKER_COLS - 1))
        else:
            gap_x_pt = gap_x_target_pt
    else:
        gap_x_pt = 0.0

    # ì„¸ë¡œëŠ” ê¸°ë³¸ "0", í˜¹ì‹œë¼ë„ ì˜¤ì°¨ë¡œ ë„˜ì¹˜ë©´ gapì„ ì¤„ì—¬ì„œ(=0 ìœ ì§€) ë§ì¶¤
    if STICKER_ROWS > 1:
        grid_h_target = (STICKER_ROWS * cell_h_pt) + ((STICKER_ROWS - 1) * gap_y_target_pt)
        if grid_h_target > usable_h + (0.1 * mm):
            gap_y_pt = max(0.0, (usable_h - (STICKER_ROWS * cell_h_pt)) / (STICKER_ROWS - 1))
        else:
            gap_y_pt = gap_y_target_pt
    else:
        gap_y_pt = 0.0

    # ì‹œì‘ì : ì¢Œì¸¡ ì—¬ë°± ê¸°ì¤€, ìƒë‹¨ ì—¬ë°± ê¸°ì¤€(ReportLabì€ ì¢Œí•˜ë‹¨ì´ (0,0))
    x0 = left_pt + (STICKER_OFFSET_X_MM * mm)
    y_top = (page_h_pt - top_pt) + (STICKER_OFFSET_Y_MM * mm)  # ì²« ì¤„ ìŠ¤í‹°ì»¤ì˜ ìœ—ë³€

    total = len(label_texts)
    page_count = (total + STICKER_PER_PAGE - 1) // STICKER_PER_PAGE if total else 1

    pad_x = 2.0 * mm
    max_text_w = cell_w_pt - (pad_x * 2)

    for p in range(page_count):
        c.setFillColor(colors.black)
        c.setFont(font_name, STICKER_FONT_SIZE)

        for r in range(STICKER_ROWS):
            for col in range(STICKER_COLS):
                slot = r * STICKER_COLS + col
                global_i = p * STICKER_PER_PAGE + slot
                if global_i >= total:
                    continue

                text = (label_texts[global_i] or "").strip()
                if not text:
                    continue

                x = x0 + col * (cell_w_pt + gap_x_pt)
                y = y_top - ((r + 1) * cell_h_pt) - (r * gap_y_pt)  # ì…€ì˜ í•˜ë‹¨

                # âœ… í–‰ë³„ í…ìŠ¤íŠ¸ ìœ„ì¹˜ ë¯¸ì„¸ë³´ì • (ìš”ì²­: 1~5í–‰ â†‘ / 12~13í–‰ â†“)
                row_shift_pt = 0.0
                if 0 <= r <= 4:
                    row_shift_pt += STICKER_TEXT_SHIFT_TOP_ROWS_MM * mm
                elif r in (11, 12):
                    row_shift_pt -= STICKER_TEXT_SHIFT_BOTTOM_ROWS_MM * mm

                lines = _wrap_for_cell(text, font_name, STICKER_FONT_SIZE, max_text_w)[:2]
                cx = x + cell_w_pt / 2.0

                if len(lines) == 1:
                    cy = y + (cell_h_pt / 2.0) - (STICKER_FONT_SIZE * 0.35) + row_shift_pt
                    _draw_center_text(c, font_name, STICKER_FONT_SIZE, cx, cy, lines[0])
                else:
                    center = y + (cell_h_pt / 2.0) + row_shift_pt
                    upper_y = center + (STICKER_LEADING * 0.25)
                    lower_y = center - (STICKER_LEADING * 0.95)
                    _draw_center_text(c, font_name, STICKER_FONT_SIZE, cx, upper_y, lines[0])
                    _draw_center_text(c, font_name, STICKER_FONT_SIZE, cx, lower_y, lines[1])

        if p < page_count - 1:
            c.showPage()

    c.save()
    return buf.getvalue()



# -------------------- TC ì£¼ë¬¸_ë“±ë¡ì–‘ì‹ ìë™ ì±„ìš°ê¸° --------------------
def _norm_header(s: str) -> str:
    s = str(s or "")
    s = s.replace("*", "")
    s = re.sub(r"\s+", "", s)
    return s.strip().lower()


def build_tc_excel_bytes(template_bytes: bytes, rows: List[Dict[str, str]]) -> bytes:
    wb = openpyxl.load_workbook(io.BytesIO(template_bytes))
    if "ì–‘ì‹" not in wb.sheetnames:
        raise ValueError("TC í…œí”Œë¦¿ì— 'ì–‘ì‹' ì‹œíŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
    ws = wb["ì–‘ì‹"]

    headers = {}
    for col in range(1, ws.max_column + 1):
        v = ws.cell(1, col).value
        if v is None:
            continue
        headers[_norm_header(v)] = col

    def col_of(label_candidates: List[str]) -> int:
        for cand in label_candidates:
            key = _norm_header(cand)
            if key in headers:
                return headers[key]
        raise KeyError(f"í•„ìˆ˜ í—¤ë”ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {label_candidates}")

    c_req = col_of(["ë°°ì†¡ìš”ì²­ì¼", "ë°°ì†¡ìš”ì²­ì¼*"])
    c_orderer = col_of(["ì£¼ë¬¸ì", "ì£¼ë¬¸ì*"])
    c_receiver = col_of(["ìˆ˜ë ¹ì", "ìˆ˜ë ¹ì*"])
    c_addr = col_of(["ìˆ˜ë ¹ìë„ë¡œëª…ì£¼ì†Œ", "ìˆ˜ë ¹ì ë„ë¡œëª… ì£¼ì†Œ", "ìˆ˜ë ¹ì ë„ë¡œëª… ì£¼ì†Œ*"])
    c_phone = col_of(["ìˆ˜ë ¹ìì—°ë½ì²˜", "ìˆ˜ë ¹ì ì—°ë½ì²˜", "ìˆ˜ë ¹ì ì—°ë½ì²˜*"])
    c_in = col_of(["ì¶œì…ë°©ë²•", "ì¶œì… ë°©ë²•"])
    c_prod = col_of(["ìƒí’ˆëª…", "ìƒí’ˆëª…*"])
    c_type = col_of(["ë°°ì†¡ìœ í˜•", "ë°°ì†¡ ìœ í˜•", "ë°°ì†¡ ìœ í˜•*"])

    start_row = 2
    for i, r in enumerate(rows):
        rr = start_row + i
        ws.cell(rr, c_req).value = r.get("ë°°ì†¡ìš”ì²­ì¼", "")
        ws.cell(rr, c_orderer).value = r.get("ì£¼ë¬¸ì", "")
        ws.cell(rr, c_receiver).value = r.get("ìˆ˜ë ¹ì", "")
        ws.cell(rr, c_addr).value = r.get("ìˆ˜ë ¹ìë„ë¡œëª…ì£¼ì†Œ", "")
        ws.cell(rr, c_phone).value = r.get("ìˆ˜ë ¹ìì—°ë½ì²˜", "")
        ws.cell(rr, c_in).value = r.get("ì¶œì…ë°©ë²•", "")
        ws.cell(rr, c_prod).value = r.get("ìƒí’ˆëª…", "")
        ws.cell(rr, c_type).value = r.get("ë°°ì†¡ìœ í˜•", "")
        # ë°°ì†¡ë°›ì„ì¥ì†ŒëŠ” ê±´ë“œë¦¬ì§€ ì•ŠìŒ

    out = io.BytesIO()
    wb.save(out)
    return out.getvalue()


# =====================================================
# (C) 1ë²ˆ ì½”ë“œ: PDF(ìŠ¤í¬ë¦°ìƒ·/í•©ê³„í‘œ) + ì¬ê³ ê´€ë¦¬
# =====================================================
def render_pdf_pages_to_images(file_bytes: bytes, zoom: float = 2.0) -> list[bytes]:
    """
    PDF ê° í˜ì´ì§€ë¥¼ PNG ìŠ¤í¬ë¦°ìƒ·ìœ¼ë¡œ ë Œë”ë§í•˜ì—¬ bytes ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
    zoom: 1.0~3.5 (í´ìˆ˜ë¡ ì„ ëª…/ìš©ëŸ‰ ì¦ê°€)
    """
    if fitz is None:
        raise RuntimeError("ìŠ¤í¬ë¦°ìƒ· ì €ì¥ì€ pymupdfê°€ í•„ìš”í•©ë‹ˆë‹¤. (pip install pymupdf)")

    doc = fitz.open(stream=file_bytes, filetype="pdf")
    out: list[bytes] = []
    mat = fitz.Matrix(zoom, zoom)

    for i in range(doc.page_count):
        page = doc.load_page(i)
        pix = page.get_pixmap(matrix=mat, alpha=False)
        out.append(pix.tobytes("png"))

    doc.close()
    return out


def merge_png_pages_to_one(png_bytes_list: list[bytes]) -> bytes:
    """
    ì—¬ëŸ¬ PNG(í˜ì´ì§€)ë¥¼ ì„¸ë¡œë¡œ ì´ì–´ë¶™ì—¬ 1ì¥ PNGë¡œ ë°˜í™˜
    Pillow(PIL) í•„ìš”
    """
    if not png_bytes_list:
        return b""

    if len(png_bytes_list) == 1:
        return png_bytes_list[0]

    if Image is None:
        return png_bytes_list[0]

    imgs = [Image.open(io.BytesIO(b)).convert("RGBA") for b in png_bytes_list]
    max_w = max(im.width for im in imgs)
    total_h = sum(im.height for im in imgs)

    canvas_img = Image.new("RGBA", (max_w, total_h), (255, 255, 255, 0))
    y = 0
    for im in imgs:
        x = (max_w - im.width) // 2
        canvas_img.paste(im, (x, y))
        y += im.height

    out = io.BytesIO()
    canvas_img.save(out, format="PNG", optimize=True)
    return out.getvalue()


def fmt_num(x: float, max_dec=2) -> str:
    s = f"{x:.{max_dec}f}".rstrip("0").rstrip(".")
    return s if s else "0"


def format_weight(grams: float) -> str | None:
    """kg/gë„ ìˆ«ìë§Œ: kg ì†Œìˆ˜ë¡œ í‘œì‹œ (19kg250g -> 19.25)"""
    if grams <= 0:
        return None
    kg = grams / 1000.0
    return fmt_num(kg, 3)


def parse_spec_components(spec: str):
    if not spec:
        return None

    s = spec.replace(",", "").replace(" ", "")
    s = s.replace("ã", "kg").replace("ï¼«ï¼§", "kg").replace("KG", "kg").lower()

    out = {"grams_per_unit": None, "bunch_per_unit": None, "counts_per_unit": {}}

    # âœ… 19kg250g ê°™ì€ ê²°í•© í‘œê¸° ì§€ì›
    m2 = re.search(r"(\d+(?:\.\d+)?)kg(\d+(?:\.\d+)?)g", s)
    if m2:
        kg = float(m2.group(1))
        g = float(m2.group(2))
        out["grams_per_unit"] = kg * 1000.0 + g
    else:
        mw = re.search(r"(\d+(?:\.\d+)?)(kg|g)", s)
        if mw:
            num = float(mw.group(1))
            unit = mw.group(2)
            out["grams_per_unit"] = num * 1000.0 if unit == "kg" else num

    mb = re.search(r"(\d+)ë‹¨", s)
    if mb:
        out["bunch_per_unit"] = int(mb.group(1))

    for u in COUNT_UNITS:
        mu = re.search(r"(\d+)" + re.escape(u), s)
        if mu:
            out["counts_per_unit"][u] = int(mu.group(1))

    if out["grams_per_unit"] is None and out["bunch_per_unit"] is None and not out["counts_per_unit"]:
        return None
    return out


def aggregate(items: list[tuple[str, str, float]]):
    agg = defaultdict(lambda: {"grams": 0.0, "bunch": 0.0, "counts": defaultdict(float), "unknown": defaultdict(float)})

    for product, spec, qty in items:
        try:
            q = float(qty)
        except Exception:
            q = 0.0

        comp = parse_spec_components(spec)
        if comp is None:
            agg[product]["unknown"][spec] += q
            continue

        if comp["grams_per_unit"] is not None:
            agg[product]["grams"] += float(comp["grams_per_unit"]) * q

        if comp["bunch_per_unit"] is not None:
            agg[product]["bunch"] += float(comp["bunch_per_unit"]) * q

        for unit, n in comp["counts_per_unit"].items():
            agg[product]["counts"][unit] += float(n) * q

    return agg


def _append_count_parts(parts: list[str], counts: dict):
    for u in ["ê°œ", "íŒ©", "í†µ", "ë´‰"]:
        v = counts.get(u, 0)
        if v:
            # ì†Œìˆ˜ëŠ” ê±°ì˜ ì—†ê² ì§€ë§Œ í˜¹ì‹œ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ
            if abs(v - round(v)) < 1e-9:
                parts.append(f"{int(round(v))}")
            else:
                parts.append(fmt_num(float(v), 2))


def format_total_custom(product: str, rec, pack_rules, box_rules, ea_rules,
                        allow_decimal_pack: bool, allow_decimal_box: bool) -> str:
    parts: list[str] = []

    # ë‹¨ë„ ìˆ«ìë§Œ
    if rec["bunch"]:
        if abs(rec["bunch"] - round(rec["bunch"])) < 1e-9:
            parts.append(f'{int(round(rec["bunch"]))}')
        else:
            parts.append(fmt_num(float(rec["bunch"]), 2))

    grams = float(rec["grams"])
    counts = dict(rec["counts"])

    # BOX ìš°ì„ : ë°•ìŠ¤ ê¸°ì¤€ìœ¼ë¡œ ë‚˜ëˆˆ ê°’(0.3ì²˜ëŸ¼) í‘œì‹œ (1 ë¯¸ë§Œì´ì–´ë„ í•­ìƒ í‘œì‹œ)
    if product in box_rules and grams > 0:
        box_size_kg = float(box_rules[product]["size_kg"])
        denom_g = box_size_kg * 1000.0
        boxes = grams / denom_g

        if allow_decimal_box:
            parts.append(f"{fmt_num(boxes, 2)}")
        else:
            if abs(boxes - round(boxes)) < 1e-9:
                parts.append(f"{int(round(boxes))}")
            else:
                parts.append(f"{fmt_num(boxes, 2)}")

        _append_count_parts(parts, counts)
        return " ".join(parts).strip() if parts else "0"

    # PACK / EA ì²˜ë¦¬
    pack_shown = False
    ea_shown = False

    # spec ìì²´ì— íŒ©ì´ ìˆìœ¼ë©´ ìš°ì„ 
    if counts.get("íŒ©", 0) > 0:
        v = counts.get("íŒ©", 0)
        parts.append(f"{int(round(v))}" if abs(v - round(v)) < 1e-9 else fmt_num(float(v), 2))
        pack_shown = True
        counts.pop("íŒ©", None)

    # rulesë¡œ g -> íŒ© ë³€í™˜
    elif product in pack_rules and grams > 0:
        size_g = float(pack_rules[product]["size_g"])
        packs = grams / size_g
        if allow_decimal_pack:
            parts.append(f"{fmt_num(packs, 2)}")
            pack_shown = True
        else:
            if abs(packs - round(packs)) < 1e-9:
                parts.append(f"{int(round(packs))}")
                pack_shown = True

    # íŒ©ì´ ì•ˆ ì¡í˜”ìœ¼ë©´ "ê°œ" ì²˜ë¦¬
    if not pack_shown:
        if counts.get("ê°œ", 0) > 0:
            v = counts.get("ê°œ", 0)
            parts.append(f"{int(round(v))}" if abs(v - round(v)) < 1e-9 else fmt_num(float(v), 2))
            ea_shown = True
            counts.pop("ê°œ", None)

        elif product in ea_rules and grams > 0:
            size_g = float(ea_rules[product]["size_g"])
            eas = grams / size_g
            # ì •ìˆ˜ë¡œ ë”± ë–¨ì–´ì§ˆ ë•Œë§Œ í‘œì‹œ(ì•„ë‹ˆë©´ ì¤‘ëŸ‰ kg ì†Œìˆ˜ë¡œ)
            if abs(eas - round(eas)) < 1e-9:
                parts.append(f"{int(round(eas))}")
                ea_shown = True

    # íŒ©ë„ ê°œë„ ì•ˆ ì¡íˆë©´ ì¤‘ëŸ‰(kg ì†Œìˆ˜)
    if not pack_shown and not ea_shown:
        w = format_weight(grams)
        if w:
            parts.append(w)

    _append_count_parts(parts, counts)
    return " ".join(parts).strip() if parts else "0"


def to_3_per_row(df: pd.DataFrame, n: int = 3) -> pd.DataFrame:
    """
    âœ… ì„¸ë¡œ ìš°ì„  ë°°ì¹˜(ìœ„â†’ì•„ë˜), ê·¸ ë‹¤ìŒ ì—´ë¡œ ì´ë™
    n=3ì´ë©´ 1ì—´ì„ ìœ„â†’ì•„ë˜ë¡œ ë‹¤ ì±„ìš´ ë’¤ 2ì—´, 3ì—´ ìˆœì„œ
    """
    if df is None or len(df) == 0:
        row = {}
        for c in range(n):
            row[f"ì œí’ˆëª…{c+1}"] = ""
            row[f"í•©ê³„{c+1}"] = ""
        return pd.DataFrame([row])

    total = len(df)
    rows_count = math.ceil(total / n)

    out = []
    for r in range(rows_count):
        row = {}
        for c in range(n):
            idx = c * rows_count + r  # ì„¸ë¡œ ìš°ì„ 
            if idx < total:
                row[f"ì œí’ˆëª…{c+1}"] = df.iloc[idx]["ì œí’ˆëª…"]
                row[f"í•©ê³„{c+1}"] = df.iloc[idx]["í•©ê³„"]
            else:
                row[f"ì œí’ˆëª…{c+1}"] = ""
                row[f"í•©ê³„{c+1}"] = ""
        out.append(row)

    return pd.DataFrame(out)


def make_pdf_bytes(df: pd.DataFrame, title: str) -> bytes:
    """
    1ë²ˆ ì½”ë“œ ìŠ¤íƒ€ì¼(landscape A4 + NanumGothic í°íŠ¸) ìœ ì§€
    """
    font_path = os.path.join("fonts", "NanumGothic.ttf")
    font_name = "NanumGothic"

    if not os.path.exists(font_path):
        raise RuntimeError(f"í°íŠ¸ íŒŒì¼ì„ ëª» ì°¾ìŒ: {font_path} (fonts í´ë”/íŒŒì¼ëª… í™•ì¸)")

    if font_name not in pdfmetrics.getRegisteredFontNames():
        pdfmetrics.registerFont(TTFont(font_name, font_path))
        pdfmetrics.registerFontFamily(
            font_name, normal=font_name, bold=font_name, italic=font_name, boldItalic=font_name
        )

    buf = io.BytesIO()
    doc = SimpleDocTemplate(
        buf, pagesize=landscape(A4),
        leftMargin=18, rightMargin=18, topMargin=18, bottomMargin=18
    )

    styles = getSampleStyleSheet()
    title_style = styles["Title"].clone("KTitle")
    title_style.fontName = font_name

    cell_style = ParagraphStyle(
        "KCell", fontName=font_name, fontSize=10, leading=12,
        alignment=1, wordWrap="CJK"
    )
    header_style = ParagraphStyle(
        "KHeader", fontName=font_name, fontSize=10, leading=12,
        alignment=1, wordWrap="CJK"
    )

    elements = [Paragraph(title, title_style), Spacer(1, 12)]
    safe_df = df.fillna("").astype(str)

    header = [Paragraph(str(c), header_style) for c in safe_df.columns]
    body = [[Paragraph(str(v), cell_style) for v in row] for row in safe_df.values.tolist()]
    data = [header] + body

    page_w, _ = landscape(A4)
    usable_w = page_w - 36
    col_w = usable_w / max(1, len(safe_df.columns))
    col_widths = [col_w] * len(safe_df.columns)

    table = Table(data, repeatRows=1, colWidths=col_widths)
    table.setStyle(TableStyle([
        ("FONTNAME", (0, 0), (-1, -1), font_name),
        ("BACKGROUND", (0, 0), (-1, 0), colors.lightgrey),
        ("GRID", (0, 0), (-1, -1), 0.5, colors.grey),
        ("VALIGN", (0, 0), (-1, -1), "MIDDLE"),
        ("TOPPADDING", (0, 0), (-1, -1), 6),
        ("BOTTOMPADDING", (0, 0), (-1, -1), 6),
    ]))

    elements.append(table)
    doc.build(elements)
    return buf.getvalue()


# =====================================================
# ì¬ê³ ê´€ë¦¬ (1ë²ˆ ì½”ë“œ)
# =====================================================
INVENTORY_COLUMNS = [
    "ìƒí’ˆëª…",
    "ì¬ê³ ",
    "ì…ê³ ",
    "ë³´ìœ ìˆ˜ëŸ‰",
    "1ì°¨",
    "2ì°¨",
    "3ì°¨",
    "ì£¼ë¬¸ìˆ˜ëŸ‰",
    "ë‚¨ì€ìˆ˜ëŸ‰",
]


def _coerce_num_series(s: pd.Series) -> pd.Series:
    """ìˆ«ì/ì†Œìˆ˜ í—ˆìš© (ë¹ˆê°’/ë¬¸ì -> 0)"""
    return pd.to_numeric(s, errors="coerce").fillna(0.0).astype(float)


def compute_inventory_df(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()

    if "ìƒí’ˆëª…" not in df.columns:
        df.insert(0, "ìƒí’ˆëª…", "")

    for col in ["ì¬ê³ ", "ì…ê³ ", "1ì°¨", "2ì°¨", "3ì°¨"]:
        if col not in df.columns:
            df[col] = 0

    for col in ["ì¬ê³ ", "ì…ê³ ", "1ì°¨", "2ì°¨", "3ì°¨"]:
        df[col] = _coerce_num_series(df[col])

    df["ìƒí’ˆëª…"] = df["ìƒí’ˆëª…"].fillna("").astype(str).str.strip()

    def _to_decimal(v):
        if v is None:
            return Decimal("0")
        try:
            if isinstance(v, float) and math.isnan(v):
                return Decimal("0")
            return Decimal(str(v))
        except Exception:
            return Decimal("0")

    stock_dec = [_to_decimal(v) for v in df["ì¬ê³ "].tolist()]
    in_dec = [_to_decimal(v) for v in df["ì…ê³ "].tolist()]
    one_dec = [_to_decimal(v) for v in df["1ì°¨"].tolist()]
    two_dec = [_to_decimal(v) for v in df["2ì°¨"].tolist()]
    three_dec = [_to_decimal(v) for v in df["3ì°¨"].tolist()]

    have_dec = [a + b for a, b in zip(stock_dec, in_dec)]
    order_dec = [a + b + c for a, b, c in zip(one_dec, two_dec, three_dec)]
    remain_dec = [a - b for a, b in zip(have_dec, order_dec)]

    df["ë³´ìœ ìˆ˜ëŸ‰"] = [float(x) for x in have_dec]
    df["ì£¼ë¬¸ìˆ˜ëŸ‰"] = [float(x) for x in order_dec]
    df["ë‚¨ì€ìˆ˜ëŸ‰"] = [float(x) for x in remain_dec]

    for c in ["ë³´ìœ ìˆ˜ëŸ‰", "ì£¼ë¬¸ìˆ˜ëŸ‰", "ë‚¨ì€ìˆ˜ëŸ‰"]:
        df[c] = pd.to_numeric(df[c], errors="coerce").fillna(0.0)
        df[c] = df[c].mask(df[c].abs() < 1e-12, 0.0)

    return df[INVENTORY_COLUMNS]


def sort_inventory_df(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    fixed_index = {name: i for i, name in enumerate(FIXED_PRODUCT_ORDER)}

    def _rank(name: str) -> int:
        return fixed_index.get(name, 10_000)

    df["__rank"] = df["ìƒí’ˆëª…"].apply(lambda x: _rank(str(x).strip()))
    df = df.sort_values(by=["__rank", "ìƒí’ˆëª…"], kind="mergesort").drop(columns=["__rank"])
    return df


def load_inventory_df() -> pd.DataFrame:
    if os.path.exists(INVENTORY_FILE):
        try:
            df = pd.read_csv(INVENTORY_FILE, encoding="utf-8-sig")
        except Exception:
            df = pd.read_csv(INVENTORY_FILE, encoding="utf-8", errors="ignore")
    else:
        df = pd.DataFrame({"ìƒí’ˆëª…": FIXED_PRODUCT_ORDER})

    existing = set(df.get("ìƒí’ˆëª…", pd.Series(dtype=str)).fillna("").astype(str).str.strip())
    missing = [p for p in FIXED_PRODUCT_ORDER if p not in existing]
    if missing:
        df = pd.concat([df, pd.DataFrame({"ìƒí’ˆëª…": missing})], ignore_index=True)

    df = compute_inventory_df(df)
    df = sort_inventory_df(df)
    df = df[df["ìƒí’ˆëª…"].astype(str).str.strip() != ""].reset_index(drop=True)
    return df


def save_inventory_df(df: pd.DataFrame) -> None:
    df.to_csv(INVENTORY_FILE, index=False, encoding="utf-8-sig")


def parse_sum_to_number(total_str: str) -> float:
    """ì œí’ˆë³„í•©ê³„ 'í•©ê³„' ë¬¸ìì—´ì—ì„œ ì²« ë²ˆì§¸ ìˆ«ìë§Œ ë½‘ì•„ ë“±ë¡ìš© ìˆ˜ì¹˜ë¡œ ì‚¬ìš©"""
    s = (total_str or "").strip()
    nums = re.findall(r"[-+]?\d*\.?\d+", s)
    if not nums:
        return 0.0
    try:
        return float(nums[0])
    except Exception:
        return 0.0


def register_sum_to_inventory(sum_df_long: pd.DataFrame, target_col: str, add_mode: bool = False):
    """ì œí’ˆë³„í•©ê³„(df_long)ë¥¼ ì¬ê³ ê´€ë¦¬ì˜ 1ì°¨/2ì°¨/3ì°¨ ì¤‘ í•˜ë‚˜ë¡œ ë“±ë¡(ìƒí’ˆëª…ì´ ìˆëŠ” ê²ƒë§Œ)"""
    if sum_df_long is None or len(sum_df_long) == 0:
        return 0, []

    if "inventory_df" in st.session_state:
        inv = st.session_state["inventory_df"].copy()
    else:
        inv = load_inventory_df()

    inv = compute_inventory_df(inv)
    inv_names = inv["ìƒí’ˆëª…"].fillna("").astype(str).str.strip()
    name_to_idx = {n: i for i, n in enumerate(inv_names)}

    skipped = []
    updated = 0

    for _, r in sum_df_long.iterrows():
        name = str(r.get("ì œí’ˆëª…", "")).strip()
        if not name:
            continue
        if name not in name_to_idx:
            skipped.append(name)
            continue

        qty = parse_sum_to_number(str(r.get("í•©ê³„", "0")))
        i = name_to_idx[name]

        if add_mode:
            inv.at[i, target_col] = float(inv.at[i, target_col]) + float(qty)
        else:
            inv.at[i, target_col] = float(qty)

        updated += 1

    inv = compute_inventory_df(inv)
    inv = sort_inventory_df(inv).reset_index(drop=True)

    st.session_state["inventory_df"] = inv
    save_inventory_df(inv)

    return updated, skipped


def inventory_df_to_xlsx_bytes(df: pd.DataFrame) -> bytes:
    buf = io.BytesIO()
    with pd.ExcelWriter(buf, engine="openpyxl") as writer:
        df.to_excel(writer, index=False, sheet_name="ì¬ê³ í‘œ")
        ws = writer.sheets["ì¬ê³ í‘œ"]
        ws.freeze_panes = "B2"
        widths = {"A": 16, "B": 8, "C": 8, "D": 10, "E": 8, "F": 8, "G": 8, "H": 10, "I": 10}
        for col, w in widths.items():
            ws.column_dimensions[col].width = w
    return buf.getvalue()


# =====================================================
# âœ… (í•µì‹¬ ë³€ê²½) ì—‘ì…€ ìš”ì•½(summary_df) â†’ 1ë²ˆ ì œí’ˆë³„í•©ê³„(í•©ê³„) ê³„ì‚°
# =====================================================
def summary_to_items(summary_df: pd.DataFrame, default_unit: str) -> list[tuple[str, str, float]]:
    """
    2ë²ˆ ì½”ë“œ ê²°ê³¼(ì œí’ˆëª…/êµ¬ë¶„/ìˆ˜ëŸ‰)ë¥¼ 1ë²ˆ ì½”ë“œ aggregate() ì…ë ¥ í˜•íƒœë¡œ ë³€í™˜.
    - êµ¬ë¶„ì´ ë¹„ì–´ìˆìœ¼ë©´ default_unit(ê¸°ë³¸ë‹¨ìœ„)ë¡œ 1ê°œ ì²˜ë¦¬: "1ê°œ" ê°™ì€ spec ìƒì„±
    """
    items: list[tuple[str, str, float]] = []
    if summary_df is None or len(summary_df) == 0:
        return items

    default_unit = normalize_text(default_unit) or "ê°œ"

    for _, r in summary_df.iterrows():
        product = str(r.get("ì œí’ˆëª…", "")).strip()
        if not product:
            continue

        spec = str(r.get("êµ¬ë¶„", "") or "").strip()
        if spec.lower() in ("nan", "none"):
            spec = ""
        if spec in ("", "-"):
            spec = f"1{default_unit}"

        try:
            qty = float(r.get("ìˆ˜ëŸ‰", 0) if r.get("ìˆ˜ëŸ‰", 0) is not None else 0)
        except Exception:
            qty = 0.0

        if qty == 0:
            continue

        items.append((product, spec, qty))

    return items


def compute_product_totals_from_summary(
    summary_df: pd.DataFrame,
    pack_rules,
    box_rules,
    ea_rules,
    allow_decimal_pack: bool,
    allow_decimal_box: bool,
    default_unit: str,
) -> tuple[pd.DataFrame, pd.DataFrame]:
    """
    ë°˜í™˜: (df_long[ì œí’ˆëª…, í•©ê³„], df_wide[3ì—´ ë°°ì¹˜])
    """
    items = summary_to_items(summary_df, default_unit=default_unit)
    agg = aggregate(items)

    rows = []
    fixed_set = set(FIXED_PRODUCT_ORDER)

    for product in FIXED_PRODUCT_ORDER:
        if product in agg:
            total_str = format_total_custom(
                product, agg[product],
                pack_rules, box_rules, ea_rules,
                allow_decimal_pack=allow_decimal_pack,
                allow_decimal_box=allow_decimal_box,
            )
        else:
            total_str = "0"
        rows.append({"ì œí’ˆëª…": product, "í•©ê³„": total_str})

    rest = [p for p in agg.keys() if p not in fixed_set]
    for product in sorted(rest):
        rows.append({
            "ì œí’ˆëª…": product,
            "í•©ê³„": format_total_custom(
                product, agg[product],
                pack_rules, box_rules, ea_rules,
                allow_decimal_pack=allow_decimal_pack,
                allow_decimal_box=allow_decimal_box,
            ),
        })

    df_long = pd.DataFrame(rows)
    df_wide = to_3_per_row(df_long, 3)
    return df_long, df_wide


# =====================================================
# Streamlit UI (1ë²ˆ ì½”ë“œ ë ˆì´ì•„ì›ƒ ìœ ì§€)
# =====================================================
st.set_page_config(
    page_title="ì¬ê³ í”„ë¡œê·¸ë¨",
    page_icon="assets/favicon.png",  # âœ… 1ë²ˆ ì½”ë“œ íŒŒë¹„ì½˜/ë””ìì¸ ìœ ì§€
    layout="wide",
)

# ----- Navigation -----
if "page" not in st.session_state:
    # âœ… ìš”ì²­: ì²˜ìŒ ì—´ë©´ "ì—‘ì…€ ì—…ë¡œë“œ"ê°€ ë¨¼ì €
    st.session_state["page"] = "excel_results"

with st.sidebar:
    st.markdown("## ğŸ“Œ ë©”ë‰´")
    if st.button("ğŸ“¥ ì—‘ì…€ ì—…ë¡œë“œ", use_container_width=True):
        st.session_state["page"] = "excel_results"
        st.rerun()
    if st.button("ğŸ§¾ ì œí’ˆë³„ í•©ê³„", use_container_width=True):
        st.session_state["page"] = "product_totals"
        st.rerun()
    if st.button("ğŸ“¦ ì¬ê³ ê´€ë¦¬", use_container_width=True):
        st.session_state["page"] = "inventory"
        st.rerun()
    if st.button("ğŸ§© ìƒí’ˆëª… ë§¤ì¹­ ê·œì¹™", use_container_width=True):
        st.session_state["page"] = "mapping_rules"
        st.rerun()
    st.divider()


# =====================================================
# Pages
# =====================================================
def render_mapping_rules_page():
    # ğŸ”’ ë¹„ë°€ë²ˆí˜¸ ë³´í˜¸ (ìƒí’ˆëª… ë§¤ì¹­ ê·œì¹™)
    if "mapping_authed" not in st.session_state:
        st.session_state["mapping_authed"] = False

    if not st.session_state["mapping_authed"]:
        st.title("ğŸ”’ ìƒí’ˆëª… ë§¤ì¹­ ê·œì¹™")
        st.caption("ì´ ë©”ë‰´ëŠ” ë¹„ë°€ë²ˆí˜¸ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        with st.form("mapping_pw_form"):
            pw = st.text_input("ë¹„ë°€ë²ˆí˜¸", type="password")
            ok = st.form_submit_button("ì…ì¥", use_container_width=True)
        if ok:
            if (pw or "").strip() == "1390":
                st.session_state["mapping_authed"] = True
                st.success("ì¸ì¦ ì™„ë£Œ!")
                st.rerun()
            else:
                st.error("ë¹„ë°€ë²ˆí˜¸ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return

    st.title("ğŸ§© ìƒí’ˆëª… ë§¤ì¹­ ê·œì¹™")
    if st.button("ğŸ”“ ì ê¸ˆ í•´ì œ(ë¡œê·¸ì•„ì›ƒ)", use_container_width=False, key="mapping_logout_btn"):
        st.session_state["mapping_authed"] = False
        st.success("ì ê¸ˆ ìƒíƒœë¡œ ì „í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.")
        st.rerun()

    st.caption("ì—‘ì…€ì˜ ì‹¤ì œ ìƒí’ˆëª… â†’ í‘œì‹œë  ìƒí’ˆëª…ìœ¼ë¡œ ë§¤í•‘í•˜ê³ , í•©ì‚°ê·œì¹™(N)ë„ ì„¤ì •í•©ë‹ˆë‹¤.")

    sidebar_backup_folder()
    sidebar_expression_rules()

    mapping_rules = load_mapping_rules()
    expr = load_expression_rules()

    st.markdown(
        """
**ë§¤ì¹­ë°©ì‹ ì„¤ëª…**
- **contains**: `íŒ¨í„´`ì´ `ì—‘ì…€ ìƒí’ˆëª…` ì•ˆì— í¬í•¨ë˜ë©´ ë§¤ì¹­
- **exact**: `íŒ¨í„´`ê³¼ `ì—‘ì…€ ìƒí’ˆëª…`ì´ ì™„ì „íˆ ë™ì¼í•  ë•Œë§Œ ë§¤ì¹­
- **regex**: `íŒ¨í„´`ì„ ì •ê·œì‹ìœ¼ë¡œ í•´ì„í•´ ë§¤ì¹­

**í•©ì‚°ê·œì¹™(N)**  
- N=5, ë‹¨ìœ„ê°€ í‘œí˜„ê·œì¹™ì— í¬í•¨ëœ ê²½ìš°(ê°œ/ë´‰/í†µ/íŒ© ë“±) â†’ 8ê°œ ì£¼ë¬¸ ì‹œ `5ê°œ 1ê°œ` + `3ê°œ 1ê°œ`ë¡œ í‘œí˜„
"""
    )

    df = mapping_df_from_list(mapping_rules)
    edited = st.data_editor(
        df,
        use_container_width=True,
        num_rows="dynamic",
        hide_index=True,
        column_config={
            "enabled": st.column_config.CheckboxColumn("ì‚¬ìš©", default=True),
            "match_type": st.column_config.SelectboxColumn("ë§¤ì¹­ ë°©ì‹", options=["contains", "exact", "regex"]),
            "pattern": st.column_config.TextColumn("ì‹¤ì œ ìƒí’ˆëª…(íŒ¨í„´)", width="large"),
            "display_name": st.column_config.TextColumn("í‘œì‹œë  ìƒí’ˆëª…", width="medium"),
            "sum_rule": st.column_config.NumberColumn("í•©ì‚°ê·œì¹™(N)", min_value=2, step=1),
            "note": st.column_config.TextColumn("ë©”ëª¨", width="large"),
        },
        key="mapping_editor_main",
    )

    c1, c2 = st.columns([1, 1])
    with c1:
        if st.button("ğŸ’¾ ì €ì¥", use_container_width=True):
            cleaned = mapping_list_from_df(edited)
            save_mapping_rules(cleaned)
            st.success(f"ì €ì¥ ì™„ë£Œ! (ê·œì¹™ {len(cleaned)}ê°œ)")
            st.rerun()

    with c2:
        if st.button("ğŸ“— ì—‘ì…€ë¡œ ì €ì¥í•˜ê¸°(ë°±ì—…)", use_container_width=True):
            cleaned_map = mapping_list_from_df(edited)
            outp = backup_rules_to_excel(cleaned_map, expr)
            st.success(f"ë°±ì—… ì €ì¥ ì™„ë£Œ: {outp.name}")
            st.rerun()


def render_excel_results_page():
    st.title("ğŸ“¥ ì—‘ì…€ ì—…ë¡œë“œ")
    st.caption("ì—‘ì…€ ì—…ë¡œë“œ â†’ ì œí’ˆë³„ ì§‘ê³„ + ìˆ˜ì·¨ì¸ë³„ PDF + ìŠ¤í‹°ì»¤ìš©ì§€ PDF + TCì£¼ë¬¸_ë“±ë¡ì–‘ì‹ ìë™ì‘ì„±")
    st.markdown("---")

    if msoffcrypto is None:
        st.error("msoffcryptoê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. requirements.txtì— 'msoffcrypto-tool'ì„ ì¶”ê°€í•˜ê³  ì¬ë°°í¬í•´ ì£¼ì„¸ìš”.")
        st.stop()

    # âœ… ì´ í˜ì´ì§€ì˜ ì‚¬ì´ë“œë°”ì—ì„œë§Œ TC ë°°ì†¡ìœ í˜• ì„¤ì • + ì €ì¥ (ìš”ì²­ì‚¬í•­ ìœ ì§€)
    tc_saved = load_tc_settings()
    if "tc_type_dawn" not in st.session_state:
        st.session_state.tc_type_dawn = tc_saved["dawn"]
    if "tc_type_next" not in st.session_state:
        st.session_state.tc_type_next = tc_saved["next"]

    with st.sidebar.expander("ğŸ”§ ë°°ì†¡ë°©ë²• ì„¤ì •", expanded=False):
        st.caption("ë³€ê²½ í›„ [ì €ì¥]ì„ ëˆ„ë¥´ë©´ ë‹¤ìŒ ì‹¤í–‰ì—ë„ ê·¸ëŒ€ë¡œ ìœ ì§€ë©ë‹ˆë‹¤.")

        dawn_val = st.text_input(
            "ìƒˆë²½ë°°ì†¡ â†’ ë°°ì†¡ìœ í˜•",
            value=st.session_state.tc_type_dawn,
            key="tc_type_dawn_input",
        )

        next_val = st.text_input(
            "ìµì¼ë°°ì†¡ â†’ ë°°ì†¡ìœ í˜•",
            value=st.session_state.tc_type_next,
            key="tc_type_next_input",
        )

        if st.button("ğŸ’¾ TC ì„¤ì • ì €ì¥", use_container_width=True, key="save_tc_settings_btn"):
            dawn_val = (dawn_val or "").strip() or TC_TYPE_DAWN_DEFAULT
            next_val = (next_val or "").strip() or TC_TYPE_NEXT_DEFAULT

            st.session_state.tc_type_dawn = dawn_val
            st.session_state.tc_type_next = next_val

            save_tc_settings(dawn_val, next_val)
            st.success("TC ì„¤ì • ì €ì¥ ì™„ë£Œ")
            st.rerun()

    uploaded = st.file_uploader("ë¹„ë°€ë²ˆí˜¸(0000) ì—‘ì…€ ì—…ë¡œë“œ (.xlsx)", type=["xlsx"], key="orders_excel_uploader")
    if uploaded is None:
        st.info("ì—‘ì…€ì„ ì—…ë¡œë“œí•˜ë©´ ê²°ê³¼ í‘œì™€ ë‹¤ìš´ë¡œë“œê°€ ë‚˜íƒ€ë‚©ë‹ˆë‹¤.")
        st.stop()

    upload_day = datetime.now(KST_TZ).date()
    req_day = upload_day + timedelta(days=1)
    req_day_str = req_day.strftime("%Y-%m-%d")

    try:
        decrypted_io = decrypt_excel(uploaded.getvalue(), password=EXCEL_PASSWORD)
        excel_bytes = decrypted_io.getvalue()
        raw_df, read_meta = smart_read_orders_excel(excel_bytes)
    except Exception as e:
        st.error('ì—‘ì…€ ì½ê¸°/ë³µí˜¸í™” ì‹¤íŒ¨: ë¹„ë°€ë²ˆí˜¸ "0000" ë˜ëŠ” íŒŒì¼ í˜•ì‹ì„ í™•ì¸í•´ ì£¼ì„¸ìš”.')
        st.exception(e)
        st.stop()

    if isinstance(read_meta, dict) and read_meta.get("method") != "header=0":
        st.caption(
            f"ğŸ“Œ í—¤ë” ìë™íƒì§€: sheet={read_meta.get('sheet')} / header_row={read_meta.get('header_row')} / {read_meta.get('method')}"
        )

    col_name = find_col(raw_df, ["ìƒí’ˆëª…", "ìƒí’ˆ", "ì œí’ˆëª…"])
    col_qty = find_col(raw_df, ["ìˆ˜ëŸ‰", "ì£¼ë¬¸ìˆ˜ëŸ‰", "êµ¬ë§¤ìˆ˜ëŸ‰", "ê°œìˆ˜"])
    col_buyer = find_col(raw_df, ["êµ¬ë§¤ìëª…", "êµ¬ë§¤ì"])
    col_recv = find_col(raw_df, ["ìˆ˜ì·¨ì¸ëª…", "ìˆ˜ë ¹ì¸", "ë°›ëŠ”ì‚¬ëŒ"])
    col_addr = find_col(raw_df, ["í†µí•©ë°°ì†¡ì§€", "ë°°ì†¡ì§€", "ì£¼ì†Œ"])
    col_opt = find_col(raw_df, ["ì˜µì…˜ì •ë³´", "ì˜µì…˜", "ì„ íƒì˜µì…˜"])
    col_recv_phone = find_col(raw_df, ["ìˆ˜ì·¨ì¸ì—°ë½ì²˜", "ìˆ˜ë ¹ì¸ì—°ë½ì²˜", "ìˆ˜ì·¨ì¸ ì—°ë½ì²˜", "ìˆ˜ë ¹ì¸ ì—°ë½ì²˜", "ì „í™”ë²ˆí˜¸", "ì—°ë½ì²˜"])
    col_msg = find_col(raw_df, ["ë°°ì†¡ë©”ì„¸ì§€", "ë°°ì†¡ë©”ì‹œì§€", "ë°°ì†¡ ë©”ì‹œì§€", "ë°°ì†¡ ë©”ì„¸ì§€", "ë°°ì†¡ìš”ì²­ì‚¬í•­", "ìš”ì²­ì‚¬í•­"])

    missing = [k for k, v in {
        "ìƒí’ˆëª…": col_name,
        "ìˆ˜ëŸ‰": col_qty,
        "êµ¬ë§¤ìëª…": col_buyer,
        "ìˆ˜ì·¨ì¸ëª…": col_recv,
        "í†µí•©ë°°ì†¡ì§€": col_addr,
        "ì˜µì…˜ì •ë³´": col_opt,
        "ìˆ˜ì·¨ì¸ì—°ë½ì²˜": col_recv_phone,
        "ë°°ì†¡ë©”ì„¸ì§€": col_msg,
    }.items() if v is None]
    if missing:
        st.error(f"í•„ìˆ˜ ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {', '.join(missing)}")
        st.write("í˜„ì¬ ì»¬ëŸ¼:", list(raw_df.columns))
        st.stop()

    mapping_rules = load_mapping_rules()
    expr = load_expression_rules()
    bundle_units = get_bundle_units(expr)
    default_unit = normalize_text(expr.get("default_unit", "ê°œ")) or "ê°œ"

    work = raw_df[[col_buyer, col_recv, col_addr, col_recv_phone, col_msg, col_opt, col_name, col_qty]].copy()
    work.columns = ["êµ¬ë§¤ìëª…", "ìˆ˜ì·¨ì¸ëª…", "í†µí•©ë°°ì†¡ì§€", "ìˆ˜ì·¨ì¸ì—°ë½ì²˜", "ë°°ì†¡ë©”ì„¸ì§€", "ì˜µì…˜ì •ë³´", "ìƒí’ˆëª…", "ìˆ˜ëŸ‰"]

    work["ìƒí’ˆëª…"] = work["ìƒí’ˆëª…"].astype(str)
    work["ìˆ˜ëŸ‰"] = pd.to_numeric(work["ìˆ˜ëŸ‰"], errors="coerce")
    work["êµ¬ë¶„"] = work["ìƒí’ˆëª…"].apply(extract_variant)

    mapped = work["ìƒí’ˆëª…"].apply(lambda x: apply_mapping(x, mapping_rules))
    work["ì œí’ˆëª…"] = mapped.apply(lambda t: t[0])
    work["ë§¤ì¹­ì„±ê³µ"] = mapped.apply(lambda t: t[1])
    work["í•©ì‚°ê·œì¹™"] = mapped.apply(lambda t: t[2])

    base = work[(work["ìˆ˜ëŸ‰"].notna()) & (work["ì œí’ˆëª…"] != "")].copy()

    exploded = explode_sum_rule_rows(
        base[["ì œí’ˆëª…", "êµ¬ë¶„", "ìˆ˜ëŸ‰", "í•©ì‚°ê·œì¹™"]],
        bundle_units=bundle_units,
        default_unit=default_unit,
    )

    summary = (
        exploded.groupby(["ì œí’ˆëª…", "êµ¬ë¶„"], as_index=False)["ìˆ˜ëŸ‰"]
        .sum()
        .sort_values(["ì œí’ˆëª…", "êµ¬ë¶„"], kind="mergesort")
        .reset_index(drop=True)
    )
    summary["ìˆ˜ëŸ‰"] = summary["ìˆ˜ëŸ‰"].apply(fmt_qty)

    # âœ… ë‹¤ë¥¸ í˜ì´ì§€(ì œí’ˆë³„ í•©ê³„)ì—ì„œ ë°”ë¡œ ì“°ë„ë¡ ì €ì¥
    st.session_state["excel_summary_df"] = summary.copy()
    st.session_state["excel_default_unit"] = default_unit

    # -------------------- Results --------------------
    with st.expander("âœ… ê²°ê³¼ (ì œí’ˆëª… / êµ¬ë¶„ / ìˆ˜ëŸ‰)", expanded=False):
        st.dataframe(summary, use_container_width=True, height=520)

    with st.expander("âš ï¸ ë¯¸ë§¤ì¹­/ëˆ„ë½ í–‰ (ê·œì¹™ ì¶”ê°€ìš©)", expanded=False):
        bad = work[(work["ë§¤ì¹­ì„±ê³µ"] == False) | (work["ìˆ˜ëŸ‰"].isna())].copy()
        st.dataframe(bad.head(300), use_container_width=True)

    # ì œí’ˆë³„ ê°œìˆ˜ PDF ë‹¤ìš´ë¡œë“œ
    st.download_button(
        "â¬‡ï¸ ì œí’ˆë³„ ê°œìˆ˜ PDF ë‹¤ìš´ë¡œë“œ",
        data=build_summary_pdf(summary),
        file_name="ì œí’ˆë³„ê°œìˆ˜.pdf",
        mime="application/pdf",
        use_container_width=True,
    )

    # ìŠ¤í‹°ì»¤ PDF
    st.markdown("---")
    st.subheader("ğŸ·ï¸ ìŠ¤í‹°ì»¤ìš©ì§€ PDF")

    # âœ… ìŠ¤í‹°ì»¤ë¡œ ì¶œë ¥í•˜ì§€ ì•Šì„ ìƒí’ˆ ì„¤ì • (í¼ì³ë³´ê¸°)
    # - ì €ì¥í•œ ì œì™¸ëª©ë¡ì€ data/sticker_settings.json ì— ë‚¨ì•„ ì´í›„ì—ë„ ìë™ ì ìš©ë©ë‹ˆë‹¤.
    if "sticker_exclude_products" not in st.session_state:
        st.session_state["sticker_exclude_products"] = load_sticker_exclude()

    product_options = sorted(
        [p for p in summary["ì œí’ˆëª…"].dropna().astype(str).str.strip().unique().tolist() if p]
    )

    saved_all = st.session_state.get("sticker_exclude_products", []) or []
    saved_in_options = [p for p in saved_all if p in product_options]
    saved_outside = [p for p in saved_all if p not in product_options]

    # ê¸°ë³¸ì€ "ì €ì¥ëœ ì œì™¸ëª©ë¡"ë§Œ ì´ë²ˆ ìƒì„±ì— ì ìš© (ì €ì¥ ì „ í¸ì§‘ê°’ì€ ì ìš©ë˜ì§€ ì•ŠìŒ)
    desired_editor = [p for p in saved_in_options if p in product_options]

    if "sticker_exclude_products_editor" not in st.session_state:
        st.session_state["sticker_exclude_products_editor"] = desired_editor
    else:
        # ì—…ë¡œë“œ íŒŒì¼ì´ ë°”ë€Œì–´ ì˜µì…˜ ëª©ë¡ì´ ë‹¬ë¼ì ¸ë„ ì˜¤ë¥˜ê°€ ë‚˜ì§€ ì•Šê²Œ, í˜„ì¬ ì˜µì…˜ì— ì—†ëŠ” ê°’ì€ ì œê±°
        st.session_state["sticker_exclude_products_editor"] = [
            p for p in (st.session_state.get("sticker_exclude_products_editor") or [])
            if p in product_options
        ]

    if "sticker_exclude_products_extra" not in st.session_state:
        st.session_state["sticker_exclude_products_extra"] = ",".join(saved_outside)

    with st.expander("ğŸš« ìŠ¤í‹°ì»¤ë¡œ ì¶œë ¥í•˜ì§€ ì•Šì„ ìƒí’ˆ ì„¤ì •", expanded=False):
        st.caption("ì„ íƒí•œ ìƒí’ˆì€ ìŠ¤í‹°ì»¤ìš©ì§€ PDF ìƒì„±ì—ì„œ ì œì™¸ë©ë‹ˆë‹¤. (ì €ì¥í•˜ë©´ ë‹¤ìŒ ì‹¤í–‰/ë‹¤ë¥¸ íŒŒì¼ì—ë„ ë™ì¼ ì ìš©)")

        st.multiselect(
            "ì œì™¸í•  ìƒí’ˆ (í˜„ì¬ ì—…ë¡œë“œí•œ íŒŒì¼ì— ì¡´ì¬í•˜ëŠ” ìƒí’ˆ)",
            options=product_options,
            key="sticker_exclude_products_editor",
        )

        st.text_input(
            "ì¶”ê°€ ì œì™¸ (ì˜µì…˜ì— ì—†ëŠ” ìƒí’ˆ Â· ì‰¼í‘œë¡œ ì—¬ëŸ¬ê°œ ì…ë ¥ Â· ì •í™•íˆ ì¼ì¹˜)",
            key="sticker_exclude_products_extra",
            placeholder="ì˜ˆ: ê³ ìˆ˜,ë”œ",
        )

        if st.button("ğŸ’¾ ì œì™¸ëª©ë¡ ì €ì¥", use_container_width=True):
            _selected = st.session_state.get("sticker_exclude_products_editor", []) or []
            _extra_text = st.session_state.get("sticker_exclude_products_extra", "") or ""
            _extra = [normalize_text(x) for x in _extra_text.split(",") if normalize_text(x)]

            _merged = []
            _seen = set()
            for _p in (_selected + _extra):
                if _p and _p not in _seen:
                    _merged.append(_p)
                    _seen.add(_p)

            save_sticker_exclude(_merged)
            st.session_state["sticker_exclude_products"] = _merged
            st.success("ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ìŒ ì‹¤í–‰ì—ë„ ê·¸ëŒ€ë¡œ ì ìš©ë©ë‹ˆë‹¤.")

        st.write(
            "í˜„ì¬ ì €ì¥ëœ ê°’:",
            (", ".join(st.session_state.get("sticker_exclude_products", []) or []) or "ì—†ìŒ"),
        )

    exclude_set = set(st.session_state.get("sticker_exclude_products", []) or [])

    excluded_stickers = 0

    label_rows = []
    for _, r in summary.iterrows():
        name = str(r["ì œí’ˆëª…"]).strip()
        qty = _as_int_qty(r["ìˆ˜ëŸ‰"])

        # ì œì™¸ ìƒí’ˆì€ ìŠ¤í‹°ì»¤ ìƒì„±ì—ì„œ ì œì™¸
        if name in exclude_set:
            if qty > 0:
                excluded_stickers += qty
            continue

        var = str(r["êµ¬ë¶„"]).strip()
        label = name if var in ("", "-", "nan", "None") else f"{name}{var}"
        if qty > 0:
            label_rows.append((label, qty))
    label_rows.sort(key=lambda x: x[0])

    sticker_texts: List[str] = []
    for label, qty in label_rows:
        sticker_texts.extend([label] * qty)
    st.caption(f"ì´ {len(sticker_texts)}ê°œ Â· í˜ì´ì§€ë‹¹ 65ì¹¸ Â· ê¸€ì {STICKER_FONT_SIZE}pt Â· ìš©ì§€ 21Ã—29.5cm Â· ì—¬ë°± L/R0.4 T1.1 B1.0cm Â· ë¼ë²¨ 3.82Ã—2.11cm Â· ê°€ë¡œê°„ê²© 0.3cm(ìë™ë³´ì •) (ì œì™¸ {excluded_stickers}ê°œ)")
    st.download_button(
        "â¬‡ï¸ ìŠ¤í‹°ì»¤ìš©ì§€ PDF ë‹¤ìš´ë¡œë“œ",
        data=build_sticker_pdf(sticker_texts),
        file_name="ìŠ¤í‹°ì»¤ìš©ì§€.pdf",
        mime="application/pdf",
        use_container_width=True,
    )

    # ìˆ˜ì·¨ì¸ë³„ ì¶œë ¥
    st.markdown("---")
    st.subheader("ğŸ“„ ìˆ˜ì·¨ì¸ë³„ ì¶œë ¥ ( ìƒˆë²½ / ìµì¼ )")

    base2 = base.copy()
    base2["ë°°ì†¡êµ¬ë¶„"] = base2["ì˜µì…˜ì •ë³´"].apply(classify_delivery)
    key_cols = ["êµ¬ë§¤ìëª…", "ìˆ˜ì·¨ì¸ëª…", "í†µí•©ë°°ì†¡ì§€"]

    grp_deliv = (
        base2.groupby(key_cols)["ë°°ì†¡êµ¬ë¶„"]
        .agg(lambda x: set(x))
        .apply(decide_group_delivery)
        .reset_index()
        .rename(columns={"ë°°ì†¡êµ¬ë¶„": "ê·¸ë£¹ë°°ì†¡êµ¬ë¶„"})
    )
    base2 = base2.merge(grp_deliv, on=key_cols, how="left")

    def build_items_for_group(g: pd.DataFrame) -> Tuple[str, str]:
        g = g.sort_index()
        od = OrderedDict()
        for _, r in g.iterrows():
            prod = str(r["ì œí’ˆëª…"]).strip()
            var = str(r["êµ¬ë¶„"] or "").strip()
            qty = r["ìˆ˜ëŸ‰"]
            sr = _safe_int(r.get("í•©ì‚°ê·œì¹™", None))
            if not prod:
                continue
            if var == "":
                var = "-"
            key = (prod, var, sr)
            od[key] = od.get(key, 0.0) + float(qty)

        rows = [{"ì œí’ˆëª…": p, "êµ¬ë¶„": v, "ìˆ˜ëŸ‰": q, "í•©ì‚°ê·œì¹™": sr} for (p, v, sr), q in od.items()]
        rows_df = pd.DataFrame(rows) if rows else pd.DataFrame(columns=["ì œí’ˆëª…", "êµ¬ë¶„", "ìˆ˜ëŸ‰", "í•©ì‚°ê·œì¹™"])

        rows_ex = explode_sum_rule_rows(
            rows_df[["ì œí’ˆëª…", "êµ¬ë¶„", "ìˆ˜ëŸ‰", "í•©ì‚°ê·œì¹™"]],
            bundle_units=bundle_units,
            default_unit=default_unit,
        ) if len(rows_df) else rows_df

        od2 = OrderedDict()
        for _, rr in rows_ex.iterrows():
            k2 = (str(rr["ì œí’ˆëª…"]), str(rr["êµ¬ë¶„"]))
            od2[k2] = od2.get(k2, 0.0) + float(rr["ìˆ˜ëŸ‰"])

        parts = [f"{pname}/{v} {fmt_qty(q2)}" for (pname, v), q2 in od2.items()]
        recv_name = str(g["ìˆ˜ì·¨ì¸ëª…"].iloc[0]).strip()
        return recv_name, ", ".join(parts)

    group_entries = []
    for _, g in base2.groupby(key_cols, sort=False):
        recv_name, items_line = build_items_for_group(g)
        group_entries.append(
            {"ê·¸ë£¹ë°°ì†¡êµ¬ë¶„": str(g["ê·¸ë£¹ë°°ì†¡êµ¬ë¶„"].iloc[0]), "ìˆ˜ì·¨ì¸ëª…": recv_name, "items_line": items_line}
        )

    dawn_entries = [e for e in group_entries if e["ê·¸ë£¹ë°°ì†¡êµ¬ë¶„"] == "ìƒˆë²½ë°°ì†¡"]
    next_entries = [e for e in group_entries if e["ê·¸ë£¹ë°°ì†¡êµ¬ë¶„"] == "ìµì¼ë°°ì†¡"]

    c1, c2 = st.columns(2)
    with c1:
        st.write(f"ìƒˆë²½ë°°ì†¡: {len(dawn_entries)}ëª…")
        st.download_button(
            "â¬‡ï¸ ìƒˆë²½ë°°ì†¡ ìˆ˜ì·¨ì¸ë³„ PDF",
            data=build_recipient_pdf(dawn_entries),
            file_name="ìƒˆë²½ë°°ì†¡.pdf",
            mime="application/pdf",
            use_container_width=True,
        )

    with c2:
        st.write(f"ìµì¼ë°°ì†¡: {len(next_entries)}ëª…")
        st.download_button(
            "â¬‡ï¸ ìµì¼ë°°ì†¡ ìˆ˜ì·¨ì¸ë³„ PDF",
            data=build_recipient_pdf(next_entries),
            file_name="ìµì¼ë°°ì†¡.pdf",
            mime="application/pdf",
            use_container_width=True,
        )

    # TC ì£¼ë¬¸ ë“±ë¡
    st.markdown("---")
    st.subheader("ğŸ§¾ TCì£¼ë¬¸_ë“±ë¡ì–‘ì‹ ( ìƒˆë²½ / ìµì¼ )")

    if not TC_TEMPLATE_DEFAULT_PATH.exists():
        st.error("ì•± í´ë”ì— 'TCì£¼ë¬¸_ë“±ë¡ì–‘ì‹.xlsx' íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. GitHubì— app.pyì™€ ê°™ì´ ì˜¬ë ¤ì£¼ì„¸ìš”.")
    else:
        template_bytes = TC_TEMPLATE_DEFAULT_PATH.read_bytes()

        # ìˆ˜ì·¨ì¸ë³„ ì¶œë ¥ ìˆœì„œ(ì›ë³¸ ë“±ì¥ ìˆœì„œ)
        order_keys_df = base2[key_cols].drop_duplicates(keep="first").copy()

        def _first_nonempty(series: pd.Series) -> str:
            for v in series.tolist():
                if v is None:
                    continue
                s = str(v).strip()
                if s and s.lower() != "nan":
                    return s
            return ""

        grp_info_agg = (
            base2.groupby(key_cols, as_index=False)
            .agg(
                ê·¸ë£¹ë°°ì†¡êµ¬ë¶„=("ê·¸ë£¹ë°°ì†¡êµ¬ë¶„", "first"),
                ìˆ˜ì·¨ì¸ì—°ë½ì²˜=("ìˆ˜ì·¨ì¸ì—°ë½ì²˜", _first_nonempty),
                ë°°ì†¡ë©”ì„¸ì§€=("ë°°ì†¡ë©”ì„¸ì§€", _first_nonempty),
                êµ¬ë§¤ìëª…=("êµ¬ë§¤ìëª…", "first"),
                ìˆ˜ì·¨ì¸ëª…=("ìˆ˜ì·¨ì¸ëª…", "first"),
                í†µí•©ë°°ì†¡ì§€=("í†µí•©ë°°ì†¡ì§€", "first"),
            )
        )
        grp_info = order_keys_df.merge(grp_info_agg, on=key_cols, how="left")

        def make_tc_rows(df: pd.DataFrame, ship: str) -> List[Dict[str, str]]:
            out = []
            ship_type = st.session_state.tc_type_dawn if ship == "ìƒˆë²½ë°°ì†¡" else st.session_state.tc_type_next
            ship_type = (ship_type or "").strip() or (TC_TYPE_DAWN_DEFAULT if ship == "ìƒˆë²½ë°°ì†¡" else TC_TYPE_NEXT_DEFAULT)

            for _, r in df.iterrows():
                out.append(
                    {
                        "ë°°ì†¡ìš”ì²­ì¼": req_day_str,
                        "ì£¼ë¬¸ì": str(r["êµ¬ë§¤ìëª…"] or "").strip(),
                        "ìˆ˜ë ¹ì": str(r["ìˆ˜ì·¨ì¸ëª…"] or "").strip(),
                        "ìˆ˜ë ¹ìë„ë¡œëª…ì£¼ì†Œ": str(r["í†µí•©ë°°ì†¡ì§€"] or "").strip(),
                        "ìˆ˜ë ¹ìì—°ë½ì²˜": str(r.get("ìˆ˜ì·¨ì¸ì—°ë½ì²˜", "") or "").strip(),
                        "ì¶œì…ë°©ë²•": _clean_access_message(r.get("ë°°ì†¡ë©”ì„¸ì§€", "")),
                        "ìƒí’ˆëª…": TC_PRODUCT_NAME_FIXED,
                        "ë°°ì†¡ìœ í˜•": ship_type,
                    }
                )
            return out

        dawn_df = grp_info[grp_info["ê·¸ë£¹ë°°ì†¡êµ¬ë¶„"] == "ìƒˆë²½ë°°ì†¡"].copy()
        next_df = grp_info[grp_info["ê·¸ë£¹ë°°ì†¡êµ¬ë¶„"] == "ìµì¼ë°°ì†¡"].copy()

        cols = st.columns(2)
        with cols[0]:
            st.write(f"ìƒˆë²½ë°°ì†¡ í–‰: {len(dawn_df)} (ë°°ì†¡ìœ í˜•: {st.session_state.tc_type_dawn})")
            if len(dawn_df):
                out_bytes = build_tc_excel_bytes(template_bytes, make_tc_rows(dawn_df, "ìƒˆë²½ë°°ì†¡"))
                st.download_button(
                    "â¬‡ï¸ TCì£¼ë¬¸_ë“±ë¡ì–‘ì‹(ìƒˆë²½ë°°ì†¡) ì—‘ì…€ ë‹¤ìš´ë¡œë“œ",
                    data=out_bytes,
                    file_name="ìƒˆë²½ë°°ì†¡_ì†¡ì¥.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    use_container_width=True,
                )

        with cols[1]:
            st.write(f"ìµì¼ë°°ì†¡ í–‰: {len(next_df)} (ë°°ì†¡ìœ í˜•: {st.session_state.tc_type_next})")
            if len(next_df):
                out_bytes = build_tc_excel_bytes(template_bytes, make_tc_rows(next_df, "ìµì¼ë°°ì†¡"))
                st.download_button(
                    "â¬‡ï¸ TCì£¼ë¬¸_ë“±ë¡ì–‘ì‹(ìµì¼ë°°ì†¡) ì—‘ì…€ ë‹¤ìš´ë¡œë“œ",
                    data=out_bytes,
                    file_name="ìµì¼ë°°ì†¡_ì†¡ì¥.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    use_container_width=True,
                )


def render_product_totals_page():
    st.title("ğŸ§¾ ì œí’ˆë³„ í•©ê³„ (PACK/BOX/EA ê·œì¹™ ì ìš©)")
    st.caption("âœ… 1ë²ˆ ì½”ë“œ ë””ìì¸ ê·¸ëŒ€ë¡œ + PDF ì—…ë¡œë“œ ì—†ì´, ì—‘ì…€ ê²°ê³¼(ì œí’ˆë³„ ê°œìˆ˜)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìë™ ê³„ì‚°í•©ë‹ˆë‹¤.")

    summary_df = st.session_state.get("excel_summary_df")
    default_unit = st.session_state.get("excel_default_unit", "ê°œ")

    if summary_df is None or len(summary_df) == 0:
        st.info("ë¨¼ì € [ğŸ“¥ ì—‘ì…€ ì—…ë¡œë“œ] í˜ì´ì§€ì—ì„œ ì—‘ì…€ì„ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")
        if st.button("ğŸ“¥ ì—‘ì…€ ì—…ë¡œë“œë¡œ ì´ë™", use_container_width=True):
            st.session_state["page"] = "excel_results"
            st.rerun()
        return

    # (1) PACK/BOX/EA ê·œì¹™ ì‚¬ì´ë“œë°” (1ë²ˆ ì½”ë“œ ìœ ì§€)
    if "rules_text" not in st.session_state:
        st.session_state["rules_text"] = load_rules_text()

    allow_decimal_pack = False
    allow_decimal_box = True

    with st.sidebar:
        st.subheader("âš™ï¸ ì œí’ˆë³„ í•©ê³„ í‘œí˜„ ê·œì¹™")

        with st.expander("ğŸ§© PACK/BOX/EA ê·œì¹™", expanded=False):
            up = st.file_uploader("rules.txt ì—…ë¡œë“œ(ì„ íƒ)", type=["txt"], key="rules_uploader")
            if up is not None:
                st.session_state["rules_text"] = up.getvalue().decode("utf-8", errors="ignore")

            st.text_area("ê·œì¹™", key="rules_text", height=260)

            colA, colB = st.columns(2)
            allow_decimal_pack = colA.checkbox("íŒ© ì†Œìˆ˜ í—ˆìš©", value=False, key="allow_decimal_pack")
            allow_decimal_box = colB.checkbox("ë°•ìŠ¤ ì†Œìˆ˜ í—ˆìš©", value=True, key="allow_decimal_box")

            with st.form("add_rule_form", clear_on_submit=False):
                st.markdown("**ê·œì¹™ ì¶”ê°€/ì—…ë°ì´íŠ¸**")
                r_type = st.selectbox("TYPE", ["íŒ©", "ê°œ", "ë°•ìŠ¤"])
                r_name = st.text_input("ìƒí’ˆëª…(ì›ë³¸ ì œí’ˆëª…ê³¼ ë™ì¼)", value="")
                r_val = st.text_input("ê°’(PACK=1íŒ© g, BOX=1ë°•ìŠ¤ kg, EA=1ê°œ g)", value="")
                submitted = st.form_submit_button("ì¶”ê°€/ì—…ë°ì´íŠ¸")
                if submitted:
                    st.session_state["rules_text"] = upsert_rule(
                        st.session_state["rules_text"], r_type, r_name, r_val
                    )
                    st.success("ê·œì¹™ ë°˜ì˜ ì™„ë£Œ!")

            col1, col2 = st.columns(2)
            if col1.button("rules.txtë¡œ ì €ì¥(ë¡œì»¬ìš©)", key="save_rules_txt"):
                try:
                    save_rules_text(st.session_state["rules_text"])
                    st.success("rules.txt ì €ì¥ ì™„ë£Œ!")
                except Exception as e:
                    st.error(f"ì €ì¥ ì‹¤íŒ¨: {e}")

            col2.download_button(
                "rules.txt ë‹¤ìš´ë¡œë“œ",
                data=st.session_state["rules_text"].encode("utf-8"),
                file_name="rules.txt",
                mime="text/plain",
            )

    pack_rules, box_rules, ea_rules = parse_rules(st.session_state["rules_text"])

    # (2) ì—‘ì…€ ìš”ì•½ ê¸°ë°˜ìœ¼ë¡œ ì œí’ˆë³„ í•©ê³„ ê³„ì‚°
    df_long, df_wide = compute_product_totals_from_summary(
        summary_df=summary_df,
        pack_rules=pack_rules,
        box_rules=box_rules,
        ea_rules=ea_rules,
        allow_decimal_pack=allow_decimal_pack,
        allow_decimal_box=allow_decimal_box,
        default_unit=default_unit,
    )

    st.session_state["last_sum_df_long"] = df_long.copy()

    st.subheader("ğŸ§¾ ì œí’ˆë³„ í•©ê³„")
    st.dataframe(df_wide, use_container_width=True, hide_index=True)

    # (3) ë‹¤ìš´ë¡œë“œ + ì¬ê³ ë“±ë¡(1ë²ˆ ì½”ë“œ ê·¸ëŒ€ë¡œ)
    try:
        pdf_bytes = make_pdf_bytes(df_wide, "ì œí’ˆë³„ í•©ê³„")

        sum_imgs = render_pdf_pages_to_images(pdf_bytes, zoom=3.0)
        sum_png_one = merge_png_pages_to_one(sum_imgs)

        c1, c2, c3 = st.columns(3)
        with c1:
            st.download_button(
                "ğŸ“„ PDF ë‹¤ìš´ë¡œë“œ(ì œí’ˆë³„í•©ê³„)",
                data=pdf_bytes,
                file_name="ì œí’ˆë³„í•©ê³„.pdf",
                mime="application/pdf",
                use_container_width=True,
            )
        with c2:
            st.download_button(
                "ğŸ–¼ï¸ ìŠ¤í¬ë¦°ìƒ·(PNG) ë‹¤ìš´ë¡œë“œ",
                data=sum_png_one,
                file_name="ì œí’ˆë³„í•©ê³„(ìŠ¤í¬ë¦°ìƒ·).png",
                mime="image/png",
                use_container_width=True,
            )
        with c3:
            if st.button("ğŸ“¦ ì¬ê³ ë“±ë¡", use_container_width=True):
                st.session_state["show_register_panel"] = True

        if st.session_state.get("show_register_panel"):
            st.markdown("#### ğŸ“ ì¬ê³ ë“±ë¡ (1ì°¨/2ì°¨/3ì°¨)")
            target = st.radio("ë“±ë¡í•  ì°¨ìˆ˜", ["1ì°¨", "2ì°¨", "3ì°¨"], horizontal=True, key="register_target")
            add_mode = st.checkbox("ê¸°ì¡´ ê°’ì— ëˆ„ì (ë”í•˜ê¸°)", value=False, key="register_add_mode")

            colR1, colR2 = st.columns([1, 3])
            with colR1:
                do_reg = st.button("âœ… ë“±ë¡", use_container_width=True, key="do_register_btn")
            with colR2:
                st.caption("â€» ì¬ê³ ê´€ë¦¬ í‘œì— **ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ìƒí’ˆëª…ë§Œ** ë“±ë¡ë©ë‹ˆë‹¤. (ì—†ëŠ” ìƒí’ˆì€ ì œì™¸)")

            if do_reg:
                sum_df = st.session_state.get("last_sum_df_long")
                updated, skipped = register_sum_to_inventory(sum_df, target_col=target, add_mode=add_mode)
                st.session_state["show_register_panel"] = False

                if skipped:
                    st.warning("ë“±ë¡ ì œì™¸(ì¬ê³ ê´€ë¦¬ ìƒí’ˆëª… ì—†ìŒ): " + ", ".join(sorted(set(skipped))))
                st.success(f"{target}ì— ë“±ë¡ ì™„ë£Œ! (ë°˜ì˜ í–‰: {updated})")
                st.info("ğŸ“¦ ì‚¬ì´ë“œë°”ì˜ 'ì¬ê³ ê´€ë¦¬'ë¡œ ì´ë™í•˜ë©´ í™•ì¸í•  ìˆ˜ ìˆì–´ìš”.")

        if Image is None and len(sum_imgs) > 1:
            st.warning("âš ï¸ Pillow(PIL)ê°€ ì—†ì–´ ì œí’ˆë³„í•©ê³„ ìŠ¤í¬ë¦°ìƒ·ì€ 1í˜ì´ì§€ë§Œ PNGë¡œ ì €ì¥ë©ë‹ˆë‹¤. ì „ì²´ë¥¼ 1ì¥ìœ¼ë¡œ í•©ì¹˜ë ¤ë©´ Pillow ì„¤ì¹˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    except Exception as e:
        st.error(f"ì œí’ˆë³„ í•©ê³„ PDF/PNG ìƒì„± ì‹¤íŒ¨: {e} (fonts/NanumGothic.ttf ë˜ëŠ” pymupdf í™•ì¸)")


def render_inventory_page():
    st.title("ì¬ê³ ê´€ë¦¬")

    # ---- ğŸ“ ë‚´ë³´ë‚´ê¸° í´ë”(ì¬ê³ ê´€ë¦¬ì—ì„œë§Œ í‘œì‹œ) ----
    with st.sidebar:
        with st.expander("ğŸ“ ë‚´ë³´ë‚´ê¸° í´ë”", expanded=False):
            dates = list_export_dates()
            if not dates:
                st.caption("ë‚´ë³´ë‚´ê¸° ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
            else:
                last = st.session_state.get("last_export_date")
                if last:
                    st.caption(f"ë§ˆì§€ë§‰ ë‚´ë³´ë‚´ê¸°: {last}")

                st.caption("â€» ì‚­ì œí•˜ë©´ ë³µêµ¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                for d in dates:
                    data = read_export_xlsx_bytes(d)
                    row1, row2 = st.columns([3, 1])

                    with row1:
                        if data is None:
                            st.caption(f"ğŸ“ {d} (íŒŒì¼ ì—†ìŒ)")
                        else:
                            st.download_button(
                                label=f"â¬‡ï¸ {d} ì¬ê³ í‘œ(.xlsx)",
                                data=data,
                                file_name=f"ì¬ê³ í‘œ_{d}.xlsx",
                                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                                use_container_width=True,
                                key=f"export_dl_{d}",
                            )

                    with row2:
                        if st.button("ğŸ—‘ï¸", use_container_width=True, key=f"export_del_{d}"):
                            ok = False
                            try:
                                ok = delete_export_date(d)
                            except Exception:
                                ok = False

                            if ok:
                                if st.session_state.get("last_export_date") == d:
                                    st.session_state["last_export_date"] = None
                                st.session_state["inventory_toast"] = f"{d} ë‚´ë³´ë‚´ê¸° ì‚­ì œ ì™„ë£Œ!"
                                st.rerun()
                            else:
                                st.error("ì‚­ì œ ì‹¤íŒ¨: í´ë”/íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")

    msg = st.session_state.pop("inventory_toast", None)
    if msg:
        st.success(msg)

    if "inventory_df" not in st.session_state:
        st.session_state["inventory_df"] = load_inventory_df()
    if "inventory_editor_version" not in st.session_state:
        st.session_state["inventory_editor_version"] = 0

    df_view = compute_inventory_df(st.session_state["inventory_df"])
    df_view = sort_inventory_df(df_view).reset_index(drop=True)
    df_view = df_view[df_view["ìƒí’ˆëª…"].astype(str).str.strip() != ""].reset_index(drop=True)

    # -------------------- ìŠ¤íƒ€ì¼ (1ë²ˆ ì½”ë“œ ìœ ì§€) --------------------
    def _remain_bg(v):
        try:
            x = float(v)
        except Exception:
            return ""
        if x < 0:
            return "background-color: #ffb3b3;"  # ì—°í•œ ë¹¨ê°•
        if 0 <= x <= 10:
            return "background-color: #ffd6e7;"  # ì—°ë¶„í™
        if x >= 30:
            return "background-color: #d6ecff;"  # ì—°íŒŒë‘
        return ""

    st.markdown(
        """
        <style>
        /* í—¤ë” í…ìŠ¤íŠ¸ Bold */
        div[data-testid="stDataEditor"] .ag-header-cell[col-id="ìƒí’ˆëª…"] .ag-header-cell-text,
        div[data-testid="stDataEditor"] .ag-header-cell[col-id="ë³´ìœ ìˆ˜ëŸ‰"] .ag-header-cell-text,
        div[data-testid="stDataEditor"] .ag-header-cell[col-id="ë‚¨ì€ìˆ˜ëŸ‰"] .ag-header-cell-text,
        div[data-testid="stDataFrame"]  .ag-header-cell[col-id="ìƒí’ˆëª…"] .ag-header-cell-text,
        div[data-testid="stDataFrame"]  .ag-header-cell[col-id="ë³´ìœ ìˆ˜ëŸ‰"] .ag-header-cell-text,
        div[data-testid="stDataFrame"]  .ag-header-cell[col-id="ë‚¨ì€ìˆ˜ëŸ‰"] .ag-header-cell-text {
            font-weight: 800 !important;
        }

        /* ì…€ ê°’ Bold(í´ë°±) */
        div[data-testid="stDataEditor"] .ag-cell[col-id="ìƒí’ˆëª…"],
        div[data-testid="stDataEditor"] .ag-cell[col-id="ë³´ìœ ìˆ˜ëŸ‰"],
        div[data-testid="stDataEditor"] .ag-cell[col-id="ë‚¨ì€ìˆ˜ëŸ‰"],
        div[data-testid="stDataEditor"] .ag-cell[col-id="ìƒí’ˆëª…"] .ag-cell-value,
        div[data-testid="stDataEditor"] .ag-cell[col-id="ë³´ìœ ìˆ˜ëŸ‰"] .ag-cell-value,
        div[data-testid="stDataEditor"] .ag-cell[col-id="ë‚¨ì€ìˆ˜ëŸ‰"] .ag-cell-value,
        div[data-testid="stDataFrame"]  .ag-cell[col-id="ìƒí’ˆëª…"],
        div[data-testid="stDataFrame"]  .ag-cell[col-id="ë³´ìœ ìˆ˜ëŸ‰"],
        div[data-testid="stDataFrame"]  .ag-cell[col-id="ë‚¨ì€ìˆ˜ëŸ‰"],
        div[data-testid="stDataFrame"]  .ag-cell[col-id="ìƒí’ˆëª…"] .ag-cell-value,
        div[data-testid="stDataFrame"]  .ag-cell[col-id="ë³´ìœ ìˆ˜ëŸ‰"] .ag-cell-value,
        div[data-testid="stDataFrame"]  .ag-cell[col-id="ë‚¨ì€ìˆ˜ëŸ‰"] .ag-cell-value {
            font-weight: 800 !important;
        }

        /* âœ… ì¬ê³ í‘œ ë°ì´í„°(ì…€) ì „ì²´ ì™¼ìª½ ì •ë ¬ (ìˆ«ì í¬í•¨) */
        div[data-testid="stDataEditor"] .ag-center-cols-container .ag-cell[col-id],
        div[data-testid="stDataFrame"]  .ag-center-cols-container .ag-cell[col-id] {
            text-align: left !important;
            justify-content: flex-start !important;
        }
        div[data-testid="stDataEditor"] .ag-center-cols-container .ag-cell[col-id] .ag-cell-wrapper,
        div[data-testid="stDataFrame"]  .ag-center-cols-container .ag-cell[col-id] .ag-cell-wrapper {
            justify-content: flex-start !important;
            width: 100% !important;
        }
        div[data-testid="stDataEditor"] .ag-center-cols-container .ag-cell[col-id] .ag-cell-value,
        div[data-testid="stDataFrame"]  .ag-center-cols-container .ag-cell[col-id] .ag-cell-value {
            text-align: left !important;
            width: 100% !important;
        }
        div[data-testid="stDataEditor"] .ag-center-cols-container .ag-cell[col-id] input,
        div[data-testid="stDataFrame"]  .ag-center-cols-container .ag-cell[col-id] input {
            text-align: left !important;
        }

        /* ìˆ«ì ê¸°ë³¸ ì˜¤ë¥¸ìª½ ì •ë ¬ í´ë˜ìŠ¤ ê°•ì œ override */
        div[data-testid="stDataEditor"] .ag-cell.ag-right-aligned,
        div[data-testid="stDataFrame"]  .ag-cell.ag-right-aligned,
        div[data-testid="stDataEditor"] .ag-cell.ag-number-cell,
        div[data-testid="stDataFrame"]  .ag-cell.ag-number-cell {
            text-align: left !important;
        }
        div[data-testid="stDataEditor"] .ag-cell.ag-right-aligned .ag-cell-wrapper,
        div[data-testid="stDataFrame"]  .ag-cell.ag-right-aligned .ag-cell-wrapper,
        div[data-testid="stDataEditor"] .ag-cell.ag-number-cell .ag-cell-wrapper,
        div[data-testid="stDataFrame"]  .ag-cell.ag-number-cell .ag-cell-wrapper {
            justify-content: flex-start !important;
            width: 100% !important;
        }

        /* (ì„ íƒ) í—¤ë”ë„ ì™¼ìª½ ì •ë ¬ */
        div[data-testid="stDataEditor"] .ag-header-cell .ag-header-cell-label,
        div[data-testid="stDataFrame"]  .ag-header-cell .ag-header-cell-label {
            justify-content: flex-start !important;
        }
        div[data-testid="stDataEditor"] .ag-header-cell-text,
        div[data-testid="stDataFrame"]  .ag-header-cell-text {
            text-align: left !important;
        }
        </style>
        """,
        unsafe_allow_html=True,
    )

    df_display = df_view.copy()

    def _fmt_num(v):
        if v is None or (isinstance(v, float) and math.isnan(v)):
            return "0"
        try:
            x = float(v)
            if abs(x) < 1e-12:
                x = 0.0
            if float(x).is_integer():
                return str(int(round(x)))
            return format(x, "g")
        except Exception:
            s = str(v).strip()
            return s if s else "0"

    for c in ["ì¬ê³ ", "ì…ê³ ", "ë³´ìœ ìˆ˜ëŸ‰", "1ì°¨", "2ì°¨", "3ì°¨", "ì£¼ë¬¸ìˆ˜ëŸ‰", "ë‚¨ì€ìˆ˜ëŸ‰"]:
        if c in df_display.columns:
            df_display[c] = df_display[c].map(_fmt_num)

    def _remain_bg_any(v):
        try:
            x = float(str(v).replace(",", "").strip())
        except Exception:
            return ""
        return _remain_bg(x)

    df_styler = (
        df_display.style
        .applymap(_remain_bg_any, subset=["ë‚¨ì€ìˆ˜ëŸ‰"])
        .set_properties(subset=["ìƒí’ˆëª…", "ë³´ìœ ìˆ˜ëŸ‰", "ë‚¨ì€ìˆ˜ëŸ‰"], **{"font-weight": "800"})
    )

    st.markdown("### ì¬ê³ í‘œ (ìˆ˜ì •/ì¶”ê°€/ì‚­ì œ ê°€ëŠ¥)")

    ver = int(st.session_state.get("inventory_editor_version", 0))
    editor_key = f"inventory_editor_{ver}"

    edited_raw = st.data_editor(
        df_styler,
        num_rows="dynamic",
        use_container_width=True,
        hide_index=True,
        disabled=["ë³´ìœ ìˆ˜ëŸ‰", "ì£¼ë¬¸ìˆ˜ëŸ‰", "ë‚¨ì€ìˆ˜ëŸ‰"],
        column_config={
            "ìƒí’ˆëª…": st.column_config.TextColumn("ìƒí’ˆëª…", required=True),
            "ì¬ê³ ": st.column_config.TextColumn("ì¬ê³ "),
            "ì…ê³ ": st.column_config.TextColumn("ì…ê³ "),
            "ë³´ìœ ìˆ˜ëŸ‰": st.column_config.TextColumn("ë³´ìœ ìˆ˜ëŸ‰"),
            "1ì°¨": st.column_config.TextColumn("1ì°¨"),
            "2ì°¨": st.column_config.TextColumn("2ì°¨"),
            "3ì°¨": st.column_config.TextColumn("3ì°¨"),
            "ì£¼ë¬¸ìˆ˜ëŸ‰": st.column_config.TextColumn("ì£¼ë¬¸ìˆ˜ëŸ‰"),
            "ë‚¨ì€ìˆ˜ëŸ‰": st.column_config.TextColumn("ë‚¨ì€ìˆ˜ëŸ‰"),
        },
        key=editor_key,
    )
    edited_raw = edited_raw.copy() if isinstance(edited_raw, pd.DataFrame) else pd.DataFrame(edited_raw)

    def _base_view(df: pd.DataFrame) -> pd.DataFrame:
        base_cols = ["ìƒí’ˆëª…", "ì¬ê³ ", "ì…ê³ ", "1ì°¨", "2ì°¨", "3ì°¨"]
        dd = df.copy()
        for c in base_cols:
            if c not in dd.columns:
                dd[c] = "" if c == "ìƒí’ˆëª…" else 0
        dd["ìƒí’ˆëª…"] = dd["ìƒí’ˆëª…"].fillna("").astype(str).str.strip()
        for c in ["ì¬ê³ ", "ì…ê³ ", "1ì°¨", "2ì°¨", "3ì°¨"]:
            dd[c] = pd.to_numeric(dd[c], errors="coerce").fillna(0.0)
        return dd[base_cols].reset_index(drop=True)

    df_base_new = _base_view(edited_raw)
    df_base_new = df_base_new[df_base_new["ìƒí’ˆëª…"].astype(str).str.strip() != ""].reset_index(drop=True)

    dup = df_base_new["ìƒí’ˆëª…"][df_base_new["ìƒí’ˆëª…"].duplicated(keep=False)]
    if len(dup) > 0:
        st.warning(f"âš ï¸ ìƒí’ˆëª…ì´ ì¤‘ë³µëœ í–‰ì´ ìˆìŠµë‹ˆë‹¤: {', '.join(sorted(set(dup.astype(str))))}")

    colA, colB, colC = st.columns([1, 1, 1])

    if colA.button("ğŸ’¾ ì €ì¥", use_container_width=True):
        df_save = compute_inventory_df(df_base_new)
        df_save = sort_inventory_df(df_save).reset_index(drop=True)
        df_save = df_save[df_save["ìƒí’ˆëª…"].astype(str).str.strip() != ""].reset_index(drop=True)

        st.session_state["inventory_df"] = df_save
        save_inventory_df(df_save)

        st.session_state["inventory_editor_version"] = ver + 1
        st.session_state["inventory_toast"] = "ì €ì¥ ì™„ë£Œ!"
        st.rerun()

    if colB.button("â†» ì´ˆê¸°í™”(0ìœ¼ë¡œ)", use_container_width=True):
        base = pd.DataFrame({"ìƒí’ˆëª…": FIXED_PRODUCT_ORDER})
        base = compute_inventory_df(base)
        base = sort_inventory_df(base).reset_index(drop=True)

        st.session_state["inventory_df"] = base
        save_inventory_df(base)

        st.session_state["inventory_editor_version"] = ver + 1
        st.session_state["inventory_toast"] = "ì´ˆê¸°í™” ì™„ë£Œ!"
        st.rerun()

    if colC.button("ğŸ“¤ ë‚´ë³´ë‚´ê¸°", use_container_width=True):
        df_export = compute_inventory_df(df_base_new)
        df_export = sort_inventory_df(df_export).reset_index(drop=True)
        df_export = df_export[df_export["ìƒí’ˆëª…"].astype(str).str.strip() != ""].reset_index(drop=True)

        try:
            date_str, _ = export_inventory_snapshot(df_export)

            df_roll = df_export.copy()
            remain = pd.to_numeric(df_roll["ë‚¨ì€ìˆ˜ëŸ‰"], errors="coerce").fillna(0.0)
            df_roll["ì¬ê³ "] = remain.clip(lower=0.0)  # âœ… ìŒìˆ˜ëŠ” ì¬ê³ ë¡œ ì´ê´€í•˜ì§€ ì•ŠìŒ
            for c in ["ì…ê³ ", "1ì°¨", "2ì°¨", "3ì°¨"]:
                df_roll[c] = 0.0

            df_roll = df_roll[["ìƒí’ˆëª…", "ì¬ê³ ", "ì…ê³ ", "1ì°¨", "2ì°¨", "3ì°¨"]]
            df_roll = compute_inventory_df(df_roll)
            df_roll = sort_inventory_df(df_roll).reset_index(drop=True)
            df_roll = df_roll[df_roll["ìƒí’ˆëª…"].astype(str).str.strip() != ""].reset_index(drop=True)

            st.session_state["inventory_df"] = df_roll
            save_inventory_df(df_roll)

            st.session_state["inventory_editor_version"] = ver + 1
            st.session_state["inventory_toast"] = (
                f"ë‚´ë³´ë‚´ê¸° ì™„ë£Œ! ë‚¨ì€ìˆ˜ëŸ‰ì„ ì¬ê³ ë¡œ ì´ê´€(ìŒìˆ˜ëŠ” 0 ì²˜ë¦¬)í–ˆê³ , ë‚˜ë¨¸ì§€ëŠ” 0ìœ¼ë¡œ ì´ˆê¸°í™”í–ˆìŠµë‹ˆë‹¤. "
                f"(ì‚¬ì´ë“œë°” â–¶ ğŸ“ ë‚´ë³´ë‚´ê¸° í´ë” â–¶ {date_str})"
            )
            st.session_state["last_export_date"] = date_str
            st.rerun()
        except Exception as e:
            st.error(f"ë‚´ë³´ë‚´ê¸° ì‹¤íŒ¨: {e}")


# =====================================================
# Router
# =====================================================
page = st.session_state.get("page", "excel_results")
if page == "mapping_rules":
    render_mapping_rules_page()
elif page == "product_totals":
    render_product_totals_page()
elif page == "inventory":
    render_inventory_page()
else:
    render_excel_results_page()
